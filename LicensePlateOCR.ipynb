{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzGZaVjziAu9S/I5Xfn7rl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harbiodun0122/OCR-for-Nigerian-Licence-Plate-/blob/master/LicensePlateOCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v6iOJsMcKy06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589c702d-854e-4d02-c83f-1b412705527c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ultralytics and fast-plate-ocr\n",
        "!pip install ultralytics fast-plate-ocr[onnx]"
      ],
      "metadata": {
        "id": "xln-QofMOum8",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b52e447-c64c-4ac3-f154-c58f8b140e72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.240-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting fast-plate-ocr[onnx]\n",
            "  Downloading fast_plate_ocr-1.0.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from fast-plate-ocr[onnx]) (4.12.0.88)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from fast-plate-ocr[onnx]) (13.9.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from fast-plate-ocr[onnx]) (4.67.1)\n",
            "Collecting onnxruntime (from fast-plate-ocr[onnx])\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting coloredlogs (from onnxruntime->fast-plate-ocr[onnx])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime->fast-plate-ocr[onnx]) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime->fast-plate-ocr[onnx]) (5.29.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->fast-plate-ocr[onnx]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->fast-plate-ocr[onnx]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->fast-plate-ocr[onnx]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->fast-plate-ocr[onnx])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.240-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Downloading fast_plate_ocr-1.0.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, ultralytics-thop, onnxruntime, fast-plate-ocr, ultralytics\n",
            "Successfully installed coloredlogs-15.0.1 fast-plate-ocr-1.0.2 humanfriendly-10.0 onnxruntime-1.23.2 ultralytics-8.3.240 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import cv2, os, re, csv\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "from fast_plate_ocr import LicensePlateRecognizer"
      ],
      "metadata": {
        "id": "OA4n1khULCLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb4fecc-148a-4b9b-d0f3-f9308ad6fb9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fast plate OCR"
      ],
      "metadata": {
        "id": "zadt9Tf56csd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fast plate ocr model\n",
        "plate_recognizer = LicensePlateRecognizer('cct-xs-v1-global-model')"
      ],
      "metadata": {
        "id": "5LnQSvDteRb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63edb443-5a9a-4c88-b5e6-5b2fb14d3727"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading cct_xs_v1_global.onnx: 100%|██████████| 2.02M/2.02M [00:00<00:00, 76.1MB/s]\n",
            "Downloading cct_xs_v1_global_plate_config.yaml: 100%|██████████| 773/773 [00:00<00:00, 1.80MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nigerian plate patterns\n",
        "NIGERIAN_PLATE_PATTERNS = [\n",
        "    r'^[A-Z]{3}\\d{3}[A-Z]{2}$',      # AAA123AA\n",
        "    r'^[A-Z]{2}\\d{3}[A-Z]{3}$',      # AA123AAA\n",
        "    r'^[A-Z]{2}\\d{2}[A-Z]\\d{2}$',    # AA12A34\n",
        "    r'^\\d{2}[A-Z]\\d{2}[A-Z]{2}$',    # 12A34AA\n",
        "    r'^[A-Z]{4}\\d{3}$',              # AAAA123\n",
        "]\n",
        "\n",
        "def format_plate_pattern(text):\n",
        "  \"\"\"\n",
        "  Fornat the plate number to the correct pattern.\n",
        "  \"\"\"\n",
        "\n",
        "  cleaned = text[0].upper().replace(' ', '').replace('_', '')\n",
        "\n",
        "  # AAA123AA -> AAA-123AA\n",
        "  if re.match(NIGERIAN_PLATE_PATTERNS[0], cleaned):\n",
        "    return f\"{cleaned[:3]}-{cleaned[3:]}\"\n",
        "\n",
        "  # AA123AAA -> AA123-AAA\n",
        "  elif re.match(NIGERIAN_PLATE_PATTERNS[1], cleaned):\n",
        "    return f\"{cleaned[:-3]}-{cleaned[-3:]}\"\n",
        "\n",
        "  # AA12A34 -> AA12-A34\n",
        "  elif re.match(NIGERIAN_PLATE_PATTERNS[2], cleaned):\n",
        "    return f\"{cleaned[:4]}-{cleaned[4:]}\"\n",
        "\n",
        "  # 12A34AA -> 12A-34AA\n",
        "  elif re.match(NIGERIAN_PLATE_PATTERNS[3], cleaned):\n",
        "    return f\"{cleaned[:3]}-{cleaned[3:]}\"\n",
        "\n",
        "  # AAAA123 -> AAAA-123\n",
        "  elif re.match(NIGERIAN_PLATE_PATTERNS[4], cleaned):\n",
        "    return f\"{cleaned[:4]}-{cleaned[4:]}\"\n",
        "\n",
        "  # If pattern do not match, return text as it is\n",
        "  else:\n",
        "    return cleaned"
      ],
      "metadata": {
        "id": "56MJx7rOsGR-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Inference on a video"
      ],
      "metadata": {
        "id": "poVI8CtfhcmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the paths\n",
        "BASE_DIR = \"/content/drive/MyDrive/Licence Plate OCR/\"\n",
        "video_path = os.path.join(BASE_DIR, \"traffic.mp4\")\n",
        "csv_path = os.path.join(BASE_DIR, \"detected_plates.csv\")\n",
        "model_path = os.path.join(BASE_DIR, \"licence_detection_output/train/weights/best.pt\")"
      ],
      "metadata": {
        "id": "ppeu9eA8xeyn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Record plate numbers in a CSV file**"
      ],
      "metadata": {
        "id": "dWx0fe0aVvzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load already-saved plates if file exists\n",
        "saved_plates = set()\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    with open(csv_path, newline=\"\", mode=\"r\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader, None)  # skip header\n",
        "        for row in reader:\n",
        "            if row:\n",
        "                saved_plates.add(row[0])\n",
        "\n",
        "# Open CSV in append mode\n",
        "csv_file = open(csv_path, mode=\"a\", newline=\"\")\n",
        "csv_writer = csv.writer(csv_file)\n",
        "\n",
        "# Write header only once\n",
        "if csv_file.tell() == 0:\n",
        "    csv_writer.writerow([\"plate_number\"])"
      ],
      "metadata": {
        "id": "mzgBvjclpm9G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Per-track OCR buffers\n",
        "ocr_buffer = defaultdict(list)\n",
        "\n",
        "# How many frames before we trust OCR\n",
        "MIN_OCR_FRAMES = 3"
      ],
      "metadata": {
        "id": "Mp-pRdRTQmxl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fully_in_frame(x1, y1, x2, y2, weight, height, margin=5):\n",
        "    return (\n",
        "        x1 > margin and\n",
        "        y1 > margin and\n",
        "        x2 < weight - margin and\n",
        "        y2 < height - margin\n",
        "    )"
      ],
      "metadata": {
        "id": "HdPVcCNXQmr6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(model_path)\n",
        "\n",
        "# Open the video file and get video details\n",
        "videoCap = cv2.VideoCapture(video_path)\n",
        "width = int(videoCap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(videoCap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frame_per_second = int(videoCap.get(cv2.CAP_PROP_FPS))\n",
        "num_frames = int(videoCap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(os.path.join(BASE_DIR, \"License Plate OCR.mp4\"), fourcc, frame_per_second, (width, height))\n",
        "\n",
        "# Loop through the video frames\n",
        "while videoCap.isOpened():\n",
        "  # Read a frame from the video\n",
        "  success, frame = videoCap.read()\n",
        "\n",
        "  if success:\n",
        "    # Run YoloV11 tracking on the frames\n",
        "    results = model.track(\n",
        "    frame,\n",
        "    persist=True,\n",
        "    tracker=\"botsort.yaml\",\n",
        "    conf=0.4,\n",
        "    iou=0.6\n",
        "    )\n",
        "\n",
        "    if results[0].boxes.id is not None:\n",
        "        boxes = results[0].boxes\n",
        "        print(\"boxes:\", boxes)\n",
        "\n",
        "        for box, track_id in zip(boxes, boxes.id):\n",
        "            track_id = int(track_id)\n",
        "            print(\"track_id: \", track_id)\n",
        "            print(\"confidence:\", box.conf[0])\n",
        "\n",
        "            if box.conf[0] < 0.4:\n",
        "                continue\n",
        "\n",
        "            # Get the coordinates\n",
        "            [x1, y1, x2, y2] = box.xyxy[0]\n",
        "\n",
        "            # Convert to ints\n",
        "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "            # Draw rectangle on detected plate\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "            # Check if detected plate is fully in frame\n",
        "            if not fully_in_frame(x1, y1, x2, y2, width, height):\n",
        "                continue\n",
        "\n",
        "            # Crop detected plate\n",
        "            plate_img = frame[y1:y2, x1:x2]\n",
        "\n",
        "            # Run OCR\n",
        "            plate = plate_recognizer.run(plate_img)\n",
        "\n",
        "            # Properly format plate number\n",
        "            formatted_plate = format_plate_pattern(plate)\n",
        "            print(\"formatted plate: \", formatted_plate)\n",
        "\n",
        "            if formatted_plate:\n",
        "                ocr_buffer[track_id].append(formatted_plate)\n",
        "\n",
        "            buffer = ocr_buffer[track_id]\n",
        "            print('buffer: ', buffer)\n",
        "\n",
        "            if len(buffer) >= MIN_OCR_FRAMES:\n",
        "                most_common, count = Counter(buffer).most_common(1)[0]\n",
        "                print(\"Most common: \", most_common, \"\\nCount: \", count)\n",
        "\n",
        "                if most_common and most_common not in saved_plates:\n",
        "                    saved_plates.add(most_common)\n",
        "\n",
        "                    # Save to CSV (append-only)\n",
        "                    csv_writer.writerow([most_common])\n",
        "                    csv_file.flush()\n",
        "\n",
        "                # Draw stabilized label\n",
        "                text_size, _ = cv2.getTextSize(most_common, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
        "                text_w, text_h = text_size\n",
        "\n",
        "                cv2.rectangle(\n",
        "                    frame,\n",
        "                    (x1, y1 - text_h - 10),\n",
        "                    (x1 + text_w + 10, y1),\n",
        "                    (255, 0, 0),\n",
        "                    -1\n",
        "                )\n",
        "\n",
        "                cv2.putText(\n",
        "                    frame,\n",
        "                    most_common,\n",
        "                    (x1 + 5, y1 - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    1,\n",
        "                    (255, 255, 255),\n",
        "                    2\n",
        "                )\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "  else:\n",
        "    # Break the loop if the end of the video is reached\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_naUxhGYP2VE",
        "outputId": "e500ee63-1808-4a25-dbc7-f9d8a00c661b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lap>=0.5.12'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 2 packages in 130ms\n",
            "Prepared 1 package in 41ms\n",
            "Installed 1 package in 1ms\n",
            " + lap==0.5.12\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 0.7s\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "0: 384x640 (no detections), 526.1ms\n",
            "Speed: 18.6ms preprocess, 526.1ms inference, 20.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 343.6ms\n",
            "Speed: 4.6ms preprocess, 343.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.6ms\n",
            "Speed: 3.5ms preprocess, 326.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.3ms\n",
            "Speed: 4.0ms preprocess, 319.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 343.2ms\n",
            "Speed: 3.9ms preprocess, 343.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 335.4ms\n",
            "Speed: 4.2ms preprocess, 335.4ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 333.7ms\n",
            "Speed: 3.8ms preprocess, 333.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 378.4ms\n",
            "Speed: 3.6ms preprocess, 378.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 554.9ms\n",
            "Speed: 8.1ms preprocess, 554.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 918.5ms\n",
            "Speed: 9.4ms preprocess, 918.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 1210.8ms\n",
            "Speed: 17.2ms preprocess, 1210.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 505.2ms\n",
            "Speed: 5.2ms preprocess, 505.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 536.8ms\n",
            "Speed: 7.8ms preprocess, 536.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 360.0ms\n",
            "Speed: 7.5ms preprocess, 360.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 340.4ms\n",
            "Speed: 3.8ms preprocess, 340.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 328.6ms\n",
            "Speed: 3.5ms preprocess, 328.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 354.4ms\n",
            "Speed: 4.0ms preprocess, 354.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 337.3ms\n",
            "Speed: 3.9ms preprocess, 337.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.2ms\n",
            "Speed: 3.9ms preprocess, 332.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 343.3ms\n",
            "Speed: 3.7ms preprocess, 343.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 320.9ms\n",
            "Speed: 3.9ms preprocess, 320.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 354.5ms\n",
            "Speed: 3.7ms preprocess, 354.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 337.8ms\n",
            "Speed: 3.7ms preprocess, 337.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.5ms\n",
            "Speed: 4.9ms preprocess, 322.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 347.0ms\n",
            "Speed: 3.7ms preprocess, 347.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 332.6ms\n",
            "Speed: 6.4ms preprocess, 332.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 341.3ms\n",
            "Speed: 3.6ms preprocess, 341.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 328.3ms\n",
            "Speed: 4.1ms preprocess, 328.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 337.6ms\n",
            "Speed: 4.0ms preprocess, 337.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 347.1ms\n",
            "Speed: 3.7ms preprocess, 347.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 319.2ms\n",
            "Speed: 3.6ms preprocess, 319.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 348.0ms\n",
            "Speed: 6.4ms preprocess, 348.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 license_plates, 325.9ms\n",
            "Speed: 3.4ms preprocess, 325.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 license_plates, 325.3ms\n",
            "Speed: 6.1ms preprocess, 325.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0., 0.])\n",
            "conf: tensor([0.8300, 0.4875])\n",
            "data: tensor([[1.3805e+03, 7.5878e+02, 1.5498e+03, 8.8289e+02, 8.0000e+00, 8.3001e-01, 0.0000e+00],\n",
            "        [1.0050e+03, 2.4530e+02, 1.1233e+03, 4.0084e+02, 9.0000e+00, 4.8749e-01, 0.0000e+00]])\n",
            "id: tensor([8., 9.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([2, 7])\n",
            "xywh: tensor([[1465.1343,  820.8344,  169.2877,  124.1177],\n",
            "        [1064.1542,  323.0674,  118.2357,  155.5367]])\n",
            "xywhn: tensor([[0.7631, 0.7600, 0.0882, 0.1149],\n",
            "        [0.5542, 0.2991, 0.0616, 0.1440]])\n",
            "xyxy: tensor([[1380.4905,  758.7755, 1549.7782,  882.8932],\n",
            "        [1005.0363,  245.2991, 1123.2720,  400.8358]])\n",
            "xyxyn: tensor([[0.7190, 0.7026, 0.8072, 0.8175],\n",
            "        [0.5235, 0.2271, 0.5850, 0.3711]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.8300)\n",
            "formatted plate:  SR253EQ\n",
            "buffer:  ['SR253EQ']\n",
            "track_id:  9\n",
            "confidence: tensor(0.4875)\n",
            "formatted plate:  14112\n",
            "buffer:  ['14112']\n",
            "\n",
            "0: 384x640 1 license_plate, 339.4ms\n",
            "Speed: 6.8ms preprocess, 339.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.8166])\n",
            "data: tensor([[1.3199e+03, 7.4664e+02, 1.4852e+03, 8.6338e+02, 8.0000e+00, 8.1659e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1402.5559,  805.0078,  165.2985,  116.7371]])\n",
            "xywhn: tensor([[0.7305, 0.7454, 0.0861, 0.1081]])\n",
            "xyxy: tensor([[1319.9066,  746.6393, 1485.2051,  863.3764]])\n",
            "xyxyn: tensor([[0.6875, 0.6913, 0.7735, 0.7994]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.8166)\n",
            "formatted plate:  SR253EQ\n",
            "buffer:  ['SR253EQ', 'SR253EQ']\n",
            "\n",
            "0: 384x640 1 license_plate, 323.1ms\n",
            "Speed: 3.9ms preprocess, 323.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.8399])\n",
            "data: tensor([[1.2568e+03, 7.3576e+02, 1.4172e+03, 8.4565e+02, 8.0000e+00, 8.3989e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1337.0000,  790.7041,  160.3365,  109.8922]])\n",
            "xywhn: tensor([[0.6964, 0.7321, 0.0835, 0.1018]])\n",
            "xyxy: tensor([[1256.8317,  735.7580, 1417.1682,  845.6502]])\n",
            "xyxyn: tensor([[0.6546, 0.6813, 0.7381, 0.7830]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.8399)\n",
            "formatted plate:  SR253EQ\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ']\n",
            "Most common:  SR253EQ \n",
            "Count:  3\n",
            "\n",
            "0: 384x640 1 license_plate, 431.3ms\n",
            "Speed: 4.0ms preprocess, 431.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.8164])\n",
            "data: tensor([[1.2002e+03, 7.2758e+02, 1.3577e+03, 8.3056e+02, 8.0000e+00, 8.1645e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1278.9495,  779.0732,  157.5858,  102.9817]])\n",
            "xywhn: tensor([[0.6661, 0.7214, 0.0821, 0.0954]])\n",
            "xyxy: tensor([[1200.1565,  727.5824, 1357.7423,  830.5641]])\n",
            "xyxyn: tensor([[0.6251, 0.6737, 0.7072, 0.7690]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.8164)\n",
            "formatted plate:  LSR-253EQ\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ']\n",
            "Most common:  SR253EQ \n",
            "Count:  3\n",
            "\n",
            "0: 384x640 2 license_plates, 1175.7ms\n",
            "Speed: 13.6ms preprocess, 1175.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0., 0.])\n",
            "conf: tensor([0.8052, 0.4345])\n",
            "data: tensor([[1.1529e+03, 7.1765e+02, 1.3067e+03, 8.1530e+02, 8.0000e+00, 8.0517e-01, 0.0000e+00],\n",
            "        [1.0024e+03, 2.4771e+02, 1.1200e+03, 3.9449e+02, 9.0000e+00, 4.3448e-01, 0.0000e+00]])\n",
            "id: tensor([8., 9.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([2, 7])\n",
            "xywh: tensor([[1229.8010,  766.4758,  153.8900,   97.6442],\n",
            "        [1061.1921,  321.0990,  117.6098,  146.7856]])\n",
            "xywhn: tensor([[0.6405, 0.7097, 0.0802, 0.0904],\n",
            "        [0.5527, 0.2973, 0.0613, 0.1359]])\n",
            "xyxy: tensor([[1152.8561,  717.6537, 1306.7461,  815.2979],\n",
            "        [1002.3873,  247.7061, 1119.9971,  394.4918]])\n",
            "xyxyn: tensor([[0.6004, 0.6645, 0.6806, 0.7549],\n",
            "        [0.5221, 0.2294, 0.5833, 0.3653]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.8052)\n",
            "formatted plate:  LSR-253EQ\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ']\n",
            "Most common:  SR253EQ \n",
            "Count:  3\n",
            "track_id:  9\n",
            "confidence: tensor(0.4345)\n",
            "formatted plate:  FA4112\n",
            "buffer:  ['14112', 'FA4112']\n",
            "\n",
            "0: 384x640 1 license_plate, 501.9ms\n",
            "Speed: 11.6ms preprocess, 501.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.7689])\n",
            "data: tensor([[1.1079e+03, 7.0977e+02, 1.2563e+03, 8.0047e+02, 8.0000e+00, 7.6892e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1182.0898,  755.1227,  148.3568,   90.6960]])\n",
            "xywhn: tensor([[0.6157, 0.6992, 0.0773, 0.0840]])\n",
            "xyxy: tensor([[1107.9115,  709.7747, 1256.2683,  800.4706]])\n",
            "xyxyn: tensor([[0.5770, 0.6572, 0.6543, 0.7412]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.7689)\n",
            "formatted plate:  LSR-253EQ\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EQ']\n",
            "Most common:  SR253EQ \n",
            "Count:  3\n",
            "\n",
            "0: 384x640 1 license_plate, 512.1ms\n",
            "Speed: 4.9ms preprocess, 512.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.7617])\n",
            "data: tensor([[1.0679e+03, 6.9826e+02, 1.2115e+03, 7.9157e+02, 8.0000e+00, 7.6168e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1139.6978,  744.9167,  143.5602,   93.3060]])\n",
            "xywhn: tensor([[0.5936, 0.6897, 0.0748, 0.0864]])\n",
            "xyxy: tensor([[1067.9176,  698.2637, 1211.4778,  791.5698]])\n",
            "xyxyn: tensor([[0.5562, 0.6465, 0.6310, 0.7329]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.7617)\n",
            "formatted plate:  LSR253E0\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0']\n",
            "Most common:  SR253EQ \n",
            "Count:  3\n",
            "\n",
            "0: 384x640 1 license_plate, 516.8ms\n",
            "Speed: 5.2ms preprocess, 516.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.7670])\n",
            "data: tensor([[1.0297e+03, 6.9148e+02, 1.1735e+03, 7.8000e+02, 8.0000e+00, 7.6702e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1101.6206,  735.7401,  143.8170,   88.5242]])\n",
            "xywhn: tensor([[0.5738, 0.6812, 0.0749, 0.0820]])\n",
            "xyxy: tensor([[1029.7120,  691.4780, 1173.5291,  780.0021]])\n",
            "xyxyn: tensor([[0.5363, 0.6403, 0.6112, 0.7222]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.7670)\n",
            "formatted plate:  LSR-253EQ\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0', 'LSR-253EQ']\n",
            "Most common:  LSR-253EQ \n",
            "Count:  4\n",
            "\n",
            "0: 384x640 1 license_plate, 510.9ms\n",
            "Speed: 5.2ms preprocess, 510.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6803])\n",
            "data: tensor([[9.9783e+02, 6.8224e+02, 1.1368e+03, 7.6673e+02, 8.0000e+00, 6.8031e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1067.2952,  724.4845,  138.9392,   84.4974]])\n",
            "xywhn: tensor([[0.5559, 0.6708, 0.0724, 0.0782]])\n",
            "xyxy: tensor([[ 997.8256,  682.2358, 1136.7648,  766.7332]])\n",
            "xyxyn: tensor([[0.5197, 0.6317, 0.5921, 0.7099]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.6803)\n",
            "formatted plate:  LSR-253EQ\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0', 'LSR-253EQ', 'LSR-253EQ']\n",
            "Most common:  LSR-253EQ \n",
            "Count:  5\n",
            "\n",
            "0: 384x640 1 license_plate, 527.9ms\n",
            "Speed: 4.5ms preprocess, 527.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6706])\n",
            "data: tensor([[9.6442e+02, 6.7641e+02, 1.1029e+03, 7.5755e+02, 8.0000e+00, 6.7064e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1033.6588,  716.9769,  138.4698,   81.1419]])\n",
            "xywhn: tensor([[0.5384, 0.6639, 0.0721, 0.0751]])\n",
            "xyxy: tensor([[ 964.4239,  676.4060, 1102.8937,  757.5479]])\n",
            "xyxyn: tensor([[0.5023, 0.6263, 0.5744, 0.7014]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.6706)\n",
            "formatted plate:  LSR-253EO\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EO']\n",
            "Most common:  LSR-253EQ \n",
            "Count:  5\n",
            "\n",
            "0: 384x640 1 license_plate, 331.9ms\n",
            "Speed: 5.2ms preprocess, 331.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6493])\n",
            "data: tensor([[9.3843e+02, 6.7259e+02, 1.0802e+03, 7.4831e+02, 8.0000e+00, 6.4934e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1009.3144,  710.4468,  141.7775,   75.7219]])\n",
            "xywhn: tensor([[0.5257, 0.6578, 0.0738, 0.0701]])\n",
            "xyxy: tensor([[ 938.4257,  672.5859, 1080.2031,  748.3078]])\n",
            "xyxyn: tensor([[0.4888, 0.6228, 0.5626, 0.6929]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.6493)\n",
            "formatted plate:  LSR-253EQ\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EO', 'LSR-253EQ']\n",
            "Most common:  LSR-253EQ \n",
            "Count:  6\n",
            "\n",
            "0: 384x640 1 license_plate, 353.0ms\n",
            "Speed: 3.6ms preprocess, 353.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6188])\n",
            "data: tensor([[9.1427e+02, 6.6715e+02, 1.0468e+03, 7.4026e+02, 8.0000e+00, 6.1877e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[980.5373, 703.7061, 132.5392,  73.1036]])\n",
            "xywhn: tensor([[0.5107, 0.6516, 0.0690, 0.0677]])\n",
            "xyxy: tensor([[ 914.2677,  667.1543, 1046.8069,  740.2579]])\n",
            "xyxyn: tensor([[0.4762, 0.6177, 0.5452, 0.6854]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.6188)\n",
            "formatted plate:  LSR-253EQ\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EO', 'LSR-253EQ', 'LSR-253EQ']\n",
            "Most common:  LSR-253EQ \n",
            "Count:  7\n",
            "\n",
            "0: 384x640 1 license_plate, 329.4ms\n",
            "Speed: 3.9ms preprocess, 329.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6469])\n",
            "data: tensor([[8.9064e+02, 6.5793e+02, 1.0194e+03, 7.3197e+02, 8.0000e+00, 6.4691e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[955.0405, 694.9481, 128.8028,  74.0357]])\n",
            "xywhn: tensor([[0.4974, 0.6435, 0.0671, 0.0686]])\n",
            "xyxy: tensor([[ 890.6392,  657.9303, 1019.4420,  731.9660]])\n",
            "xyxyn: tensor([[0.4639, 0.6092, 0.5310, 0.6777]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.6469)\n",
            "formatted plate:  LSR253E0\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EO', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0']\n",
            "Most common:  LSR-253EQ \n",
            "Count:  7\n",
            "\n",
            "0: 384x640 1 license_plate, 332.6ms\n",
            "Speed: 3.7ms preprocess, 332.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4893])\n",
            "data: tensor([[8.6893e+02, 6.5392e+02, 9.9658e+02, 7.2464e+02, 8.0000e+00, 4.8931e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[932.7552, 689.2777, 127.6437,  70.7247]])\n",
            "xywhn: tensor([[0.4858, 0.6382, 0.0665, 0.0655]])\n",
            "xyxy: tensor([[868.9333, 653.9153, 996.5770, 724.6401]])\n",
            "xyxyn: tensor([[0.4526, 0.6055, 0.5191, 0.6710]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.4893)\n",
            "formatted plate:  LSR-253EO\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EO', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0', 'LSR-253EO']\n",
            "Most common:  LSR-253EQ \n",
            "Count:  7\n",
            "\n",
            "0: 384x640 1 license_plate, 335.3ms\n",
            "Speed: 3.9ms preprocess, 335.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5683])\n",
            "data: tensor([[8.5379e+02, 6.4718e+02, 9.8130e+02, 7.1594e+02, 8.0000e+00, 5.6826e-01, 0.0000e+00]])\n",
            "id: tensor([8.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[917.5448, 681.5595, 127.5046,  68.7625]])\n",
            "xywhn: tensor([[0.4779, 0.6311, 0.0664, 0.0637]])\n",
            "xyxy: tensor([[853.7925, 647.1783, 981.2971, 715.9407]])\n",
            "xyxyn: tensor([[0.4447, 0.5992, 0.5111, 0.6629]])\n",
            "track_id:  8\n",
            "confidence: tensor(0.5683)\n",
            "formatted plate:  LSR-253EQ\n",
            "buffer:  ['SR253EQ', 'SR253EQ', 'SR253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0', 'LSR-253EQ', 'LSR-253EQ', 'LSR-253EO', 'LSR-253EQ', 'LSR-253EQ', 'LSR253E0', 'LSR-253EO', 'LSR-253EQ']\n",
            "Most common:  LSR-253EQ \n",
            "Count:  8\n",
            "\n",
            "0: 384x640 (no detections), 334.4ms\n",
            "Speed: 3.6ms preprocess, 334.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 341.1ms\n",
            "Speed: 4.1ms preprocess, 341.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.1ms\n",
            "Speed: 3.6ms preprocess, 319.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 328.1ms\n",
            "Speed: 4.1ms preprocess, 328.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 349.4ms\n",
            "Speed: 4.1ms preprocess, 349.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 329.1ms\n",
            "Speed: 4.4ms preprocess, 329.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.6ms\n",
            "Speed: 3.4ms preprocess, 326.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.0ms\n",
            "Speed: 5.4ms preprocess, 322.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 347.4ms\n",
            "Speed: 3.8ms preprocess, 347.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 349.5ms\n",
            "Speed: 3.7ms preprocess, 349.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.3ms\n",
            "Speed: 3.8ms preprocess, 319.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 329.2ms\n",
            "Speed: 4.0ms preprocess, 329.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 334.1ms\n",
            "Speed: 3.8ms preprocess, 334.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 330.8ms\n",
            "Speed: 6.8ms preprocess, 330.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 341.4ms\n",
            "Speed: 3.6ms preprocess, 341.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.6ms\n",
            "Speed: 3.7ms preprocess, 324.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 314.5ms\n",
            "Speed: 4.1ms preprocess, 314.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 350.3ms\n",
            "Speed: 5.8ms preprocess, 350.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 320.7ms\n",
            "Speed: 3.6ms preprocess, 320.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 434.4ms\n",
            "Speed: 6.7ms preprocess, 434.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 500.7ms\n",
            "Speed: 3.7ms preprocess, 500.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 507.4ms\n",
            "Speed: 4.6ms preprocess, 507.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 500.4ms\n",
            "Speed: 3.6ms preprocess, 500.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 539.9ms\n",
            "Speed: 7.5ms preprocess, 539.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 501.2ms\n",
            "Speed: 7.9ms preprocess, 501.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 531.2ms\n",
            "Speed: 4.2ms preprocess, 531.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 449.2ms\n",
            "Speed: 6.6ms preprocess, 449.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 347.4ms\n",
            "Speed: 5.2ms preprocess, 347.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.9ms\n",
            "Speed: 3.6ms preprocess, 332.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 374.5ms\n",
            "Speed: 4.2ms preprocess, 374.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 337.9ms\n",
            "Speed: 4.0ms preprocess, 337.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 333.6ms\n",
            "Speed: 3.5ms preprocess, 333.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 335.8ms\n",
            "Speed: 4.9ms preprocess, 335.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 328.8ms\n",
            "Speed: 3.4ms preprocess, 328.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 343.6ms\n",
            "Speed: 4.2ms preprocess, 343.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 327.2ms\n",
            "Speed: 3.6ms preprocess, 327.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.0ms\n",
            "Speed: 4.1ms preprocess, 326.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 352.3ms\n",
            "Speed: 4.0ms preprocess, 352.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.8ms\n",
            "Speed: 3.6ms preprocess, 322.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.1ms\n",
            "Speed: 3.7ms preprocess, 322.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 330.9ms\n",
            "Speed: 3.4ms preprocess, 330.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 317.4ms\n",
            "Speed: 4.9ms preprocess, 317.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 350.8ms\n",
            "Speed: 5.8ms preprocess, 350.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.3ms\n",
            "Speed: 6.0ms preprocess, 319.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 315.1ms\n",
            "Speed: 4.7ms preprocess, 315.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 339.6ms\n",
            "Speed: 5.3ms preprocess, 339.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.8ms\n",
            "Speed: 4.5ms preprocess, 319.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 339.5ms\n",
            "Speed: 4.0ms preprocess, 339.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.6ms\n",
            "Speed: 3.9ms preprocess, 322.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.9ms\n",
            "Speed: 3.7ms preprocess, 324.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 335.5ms\n",
            "Speed: 3.9ms preprocess, 335.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 468.6ms\n",
            "Speed: 3.9ms preprocess, 468.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 567.8ms\n",
            "Speed: 5.5ms preprocess, 567.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 520.0ms\n",
            "Speed: 5.2ms preprocess, 520.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 509.9ms\n",
            "Speed: 5.2ms preprocess, 509.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 515.7ms\n",
            "Speed: 4.8ms preprocess, 515.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 495.9ms\n",
            "Speed: 5.0ms preprocess, 495.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 523.6ms\n",
            "Speed: 5.6ms preprocess, 523.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 386.7ms\n",
            "Speed: 5.6ms preprocess, 386.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 339.7ms\n",
            "Speed: 3.6ms preprocess, 339.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.0ms\n",
            "Speed: 4.9ms preprocess, 322.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.7ms\n",
            "Speed: 3.7ms preprocess, 331.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 347.3ms\n",
            "Speed: 3.6ms preprocess, 347.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.7ms\n",
            "Speed: 6.3ms preprocess, 331.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 336.1ms\n",
            "Speed: 3.6ms preprocess, 336.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 334.0ms\n",
            "Speed: 3.5ms preprocess, 334.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 321.8ms\n",
            "Speed: 3.5ms preprocess, 321.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 350.0ms\n",
            "Speed: 3.5ms preprocess, 350.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 323.6ms\n",
            "Speed: 3.6ms preprocess, 323.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 341.0ms\n",
            "Speed: 5.3ms preprocess, 341.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 317.3ms\n",
            "Speed: 3.6ms preprocess, 317.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 325.9ms\n",
            "Speed: 5.1ms preprocess, 325.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.8178])\n",
            "data: tensor([[1.4947e+03, 8.2443e+02, 1.6818e+03, 9.4459e+02, 1.4000e+01, 8.1782e-01, 0.0000e+00]])\n",
            "id: tensor([14.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1588.2520,  884.5115,  187.1014,  120.1620]])\n",
            "xywhn: tensor([[0.8272, 0.8190, 0.0974, 0.1113]])\n",
            "xyxy: tensor([[1494.7012,  824.4305, 1681.8026,  944.5925]])\n",
            "xyxyn: tensor([[0.7785, 0.7634, 0.8759, 0.8746]])\n",
            "track_id:  14\n",
            "confidence: tensor(0.8178)\n",
            "formatted plate:  TU509XS\n",
            "buffer:  ['TU509XS']\n",
            "\n",
            "0: 384x640 1 license_plate, 322.0ms\n",
            "Speed: 3.4ms preprocess, 322.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.7555])\n",
            "data: tensor([[1.4439e+03, 8.1174e+02, 1.6375e+03, 9.2521e+02, 1.4000e+01, 7.5548e-01, 0.0000e+00]])\n",
            "id: tensor([14.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1540.6757,  868.4733,  193.6099,  113.4667]])\n",
            "xywhn: tensor([[0.8024, 0.8041, 0.1008, 0.1051]])\n",
            "xyxy: tensor([[1443.8707,  811.7400, 1637.4806,  925.2067]])\n",
            "xyxyn: tensor([[0.7520, 0.7516, 0.8529, 0.8567]])\n",
            "track_id:  14\n",
            "confidence: tensor(0.7555)\n",
            "formatted plate:  TU509XS\n",
            "buffer:  ['TU509XS', 'TU509XS']\n",
            "\n",
            "0: 384x640 1 license_plate, 333.9ms\n",
            "Speed: 6.2ms preprocess, 333.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.7161])\n",
            "data: tensor([[1.3948e+03, 7.9456e+02, 1.5801e+03, 9.0450e+02, 1.4000e+01, 7.1609e-01, 0.0000e+00]])\n",
            "id: tensor([14.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1487.4436,  849.5300,  185.3618,  109.9446]])\n",
            "xywhn: tensor([[0.7747, 0.7866, 0.0965, 0.1018]])\n",
            "xyxy: tensor([[1394.7627,  794.5577, 1580.1245,  904.5023]])\n",
            "xyxyn: tensor([[0.7264, 0.7357, 0.8230, 0.8375]])\n",
            "track_id:  14\n",
            "confidence: tensor(0.7161)\n",
            "formatted plate:  TU509XS\n",
            "buffer:  ['TU509XS', 'TU509XS', 'TU509XS']\n",
            "Most common:  TU509XS \n",
            "Count:  3\n",
            "\n",
            "0: 384x640 1 license_plate, 337.4ms\n",
            "Speed: 4.8ms preprocess, 337.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6779])\n",
            "data: tensor([[1.3516e+03, 7.8033e+02, 1.5503e+03, 8.8684e+02, 1.4000e+01, 6.7789e-01, 0.0000e+00]])\n",
            "id: tensor([14.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1450.9409,  833.5863,  198.7714,  106.5157]])\n",
            "xywhn: tensor([[0.7557, 0.7718, 0.1035, 0.0986]])\n",
            "xyxy: tensor([[1351.5552,  780.3285, 1550.3265,  886.8442]])\n",
            "xyxyn: tensor([[0.7039, 0.7225, 0.8075, 0.8212]])\n",
            "track_id:  14\n",
            "confidence: tensor(0.6779)\n",
            "formatted plate:  TU509XS\n",
            "buffer:  ['TU509XS', 'TU509XS', 'TU509XS', 'TU509XS']\n",
            "Most common:  TU509XS \n",
            "Count:  4\n",
            "\n",
            "0: 384x640 1 license_plate, 351.2ms\n",
            "Speed: 5.2ms preprocess, 351.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6096])\n",
            "data: tensor([[1.3089e+03, 7.7196e+02, 1.4937e+03, 8.6668e+02, 1.4000e+01, 6.0958e-01, 0.0000e+00]])\n",
            "id: tensor([14.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1401.2865,  819.3224,  184.7771,   94.7177]])\n",
            "xywhn: tensor([[0.7298, 0.7586, 0.0962, 0.0877]])\n",
            "xyxy: tensor([[1308.8979,  771.9636, 1493.6750,  866.6812]])\n",
            "xyxyn: tensor([[0.6817, 0.7148, 0.7780, 0.8025]])\n",
            "track_id:  14\n",
            "confidence: tensor(0.6096)\n",
            "formatted plate:  KTU-509XS\n",
            "buffer:  ['TU509XS', 'TU509XS', 'TU509XS', 'TU509XS', 'KTU-509XS']\n",
            "Most common:  TU509XS \n",
            "Count:  4\n",
            "\n",
            "0: 384x640 1 license_plate, 335.9ms\n",
            "Speed: 6.8ms preprocess, 335.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6458])\n",
            "data: tensor([[1.2727e+03, 7.6208e+02, 1.4823e+03, 8.5316e+02, 1.4000e+01, 6.4581e-01, 0.0000e+00]])\n",
            "id: tensor([14.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1377.5059,  807.6196,  209.6239,   91.0778]])\n",
            "xywhn: tensor([[0.7175, 0.7478, 0.1092, 0.0843]])\n",
            "xyxy: tensor([[1272.6938,  762.0807, 1482.3177,  853.1585]])\n",
            "xyxyn: tensor([[0.6629, 0.7056, 0.7720, 0.7900]])\n",
            "track_id:  14\n",
            "confidence: tensor(0.6458)\n",
            "formatted plate:  KII50XSS\n",
            "buffer:  ['TU509XS', 'TU509XS', 'TU509XS', 'TU509XS', 'KTU-509XS', 'KII50XSS']\n",
            "Most common:  TU509XS \n",
            "Count:  4\n",
            "\n",
            "0: 384x640 1 license_plate, 349.1ms\n",
            "Speed: 3.8ms preprocess, 349.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5753])\n",
            "data: tensor([[1.2414e+03, 7.5140e+02, 1.4349e+03, 8.3956e+02, 1.4000e+01, 5.7526e-01, 0.0000e+00]])\n",
            "id: tensor([14.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1338.1582,  795.4814,  193.4186,   88.1536]])\n",
            "xywhn: tensor([[0.6970, 0.7366, 0.1007, 0.0816]])\n",
            "xyxy: tensor([[1241.4490,  751.4047, 1434.8676,  839.5583]])\n",
            "xyxyn: tensor([[0.6466, 0.6957, 0.7473, 0.7774]])\n",
            "track_id:  14\n",
            "confidence: tensor(0.5753)\n",
            "formatted plate:  KT5009SS\n",
            "buffer:  ['TU509XS', 'TU509XS', 'TU509XS', 'TU509XS', 'KTU-509XS', 'KII50XSS', 'KT5009SS']\n",
            "Most common:  TU509XS \n",
            "Count:  4\n",
            "\n",
            "0: 384x640 1 license_plate, 319.6ms\n",
            "Speed: 4.4ms preprocess, 319.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5395])\n",
            "data: tensor([[1.2127e+03, 7.4103e+02, 1.3891e+03, 8.2922e+02, 1.4000e+01, 5.3952e-01, 0.0000e+00]])\n",
            "id: tensor([14.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1300.9072,  785.1205,  176.3680,   88.1909]])\n",
            "xywhn: tensor([[0.6776, 0.7270, 0.0919, 0.0817]])\n",
            "xyxy: tensor([[1212.7233,  741.0251, 1389.0913,  829.2159]])\n",
            "xyxyn: tensor([[0.6316, 0.6861, 0.7235, 0.7678]])\n",
            "track_id:  14\n",
            "confidence: tensor(0.5395)\n",
            "formatted plate:  KIU-509XS\n",
            "buffer:  ['TU509XS', 'TU509XS', 'TU509XS', 'TU509XS', 'KTU-509XS', 'KII50XSS', 'KT5009SS', 'KIU-509XS']\n",
            "Most common:  TU509XS \n",
            "Count:  4\n",
            "\n",
            "0: 384x640 (no detections), 356.2ms\n",
            "Speed: 3.5ms preprocess, 356.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 356.5ms\n",
            "Speed: 3.7ms preprocess, 356.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4371])\n",
            "data: tensor([[1.1637e+03, 7.1980e+02, 1.3630e+03, 8.0648e+02, 1.4000e+01, 4.3709e-01, 0.0000e+00]])\n",
            "id: tensor([14.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1263.3545,  763.1396,  199.3075,   86.6885]])\n",
            "xywhn: tensor([[0.6580, 0.7066, 0.1038, 0.0803]])\n",
            "xyxy: tensor([[1163.7007,  719.7954, 1363.0082,  806.4839]])\n",
            "xyxyn: tensor([[0.6061, 0.6665, 0.7099, 0.7467]])\n",
            "track_id:  14\n",
            "confidence: tensor(0.4371)\n",
            "formatted plate:  KI150-XSS\n",
            "buffer:  ['TU509XS', 'TU509XS', 'TU509XS', 'TU509XS', 'KTU-509XS', 'KII50XSS', 'KT5009SS', 'KIU-509XS', 'KI150-XSS']\n",
            "Most common:  TU509XS \n",
            "Count:  4\n",
            "\n",
            "0: 384x640 (no detections), 306.7ms\n",
            "Speed: 3.7ms preprocess, 306.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 436.6ms\n",
            "Speed: 4.9ms preprocess, 436.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4061])\n",
            "data: tensor([[1.1231e+03, 6.9942e+02, 1.3192e+03, 7.8728e+02, 1.4000e+01, 4.0612e-01, 0.0000e+00]])\n",
            "id: tensor([14.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1221.1521,  743.3516,  196.1891,   87.8562]])\n",
            "xywhn: tensor([[0.6360, 0.6883, 0.1022, 0.0813]])\n",
            "xyxy: tensor([[1123.0575,  699.4235, 1319.2466,  787.2797]])\n",
            "xyxyn: tensor([[0.5849, 0.6476, 0.6871, 0.7290]])\n",
            "track_id:  14\n",
            "confidence: tensor(0.4061)\n",
            "formatted plate:  MI509XS\n",
            "buffer:  ['TU509XS', 'TU509XS', 'TU509XS', 'TU509XS', 'KTU-509XS', 'KII50XSS', 'KT5009SS', 'KIU-509XS', 'KI150-XSS', 'MI509XS']\n",
            "Most common:  TU509XS \n",
            "Count:  4\n",
            "\n",
            "0: 384x640 (no detections), 514.2ms\n",
            "Speed: 7.1ms preprocess, 514.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 499.2ms\n",
            "Speed: 6.1ms preprocess, 499.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 508.8ms\n",
            "Speed: 10.9ms preprocess, 508.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 503.3ms\n",
            "Speed: 6.5ms preprocess, 503.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 502.4ms\n",
            "Speed: 5.0ms preprocess, 502.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 508.3ms\n",
            "Speed: 7.7ms preprocess, 508.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 438.1ms\n",
            "Speed: 6.6ms preprocess, 438.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 330.7ms\n",
            "Speed: 3.7ms preprocess, 330.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.6ms\n",
            "Speed: 5.4ms preprocess, 319.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 325.8ms\n",
            "Speed: 3.7ms preprocess, 325.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.9ms\n",
            "Speed: 3.6ms preprocess, 324.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 354.6ms\n",
            "Speed: 4.1ms preprocess, 354.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 340.4ms\n",
            "Speed: 3.8ms preprocess, 340.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 327.7ms\n",
            "Speed: 7.4ms preprocess, 327.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 341.9ms\n",
            "Speed: 6.1ms preprocess, 341.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 339.0ms\n",
            "Speed: 4.1ms preprocess, 339.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 348.4ms\n",
            "Speed: 4.2ms preprocess, 348.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.5ms\n",
            "Speed: 4.1ms preprocess, 323.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 321.3ms\n",
            "Speed: 3.7ms preprocess, 321.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 358.7ms\n",
            "Speed: 3.7ms preprocess, 358.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.8ms\n",
            "Speed: 4.0ms preprocess, 324.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 359.8ms\n",
            "Speed: 4.2ms preprocess, 359.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 328.4ms\n",
            "Speed: 4.2ms preprocess, 328.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 332.6ms\n",
            "Speed: 3.9ms preprocess, 332.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5008])\n",
            "data: tensor([[1.0380e+03, 6.3085e+02, 1.2078e+03, 6.8507e+02, 1.6000e+01, 5.0079e-01, 0.0000e+00]])\n",
            "id: tensor([16.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1122.9120,  657.9578,  169.8359,   54.2247]])\n",
            "xywhn: tensor([[0.5849, 0.6092, 0.0885, 0.0502]])\n",
            "xyxy: tensor([[1037.9940,  630.8455, 1207.8300,  685.0701]])\n",
            "xyxyn: tensor([[0.5406, 0.5841, 0.6291, 0.6343]])\n",
            "track_id:  16\n",
            "confidence: tensor(0.5008)\n",
            "formatted plate:  AUU509S\n",
            "buffer:  ['AUU509S']\n",
            "\n",
            "0: 384x640 (no detections), 323.4ms\n",
            "Speed: 4.6ms preprocess, 323.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 306.9ms\n",
            "Speed: 6.0ms preprocess, 306.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 302.7ms\n",
            "Speed: 4.7ms preprocess, 302.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 330.4ms\n",
            "Speed: 5.8ms preprocess, 330.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 307.3ms\n",
            "Speed: 3.6ms preprocess, 307.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 337.0ms\n",
            "Speed: 3.6ms preprocess, 337.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 306.5ms\n",
            "Speed: 3.6ms preprocess, 306.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 465.4ms\n",
            "Speed: 3.9ms preprocess, 465.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 523.3ms\n",
            "Speed: 4.9ms preprocess, 523.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 881.9ms\n",
            "Speed: 7.9ms preprocess, 881.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 501.2ms\n",
            "Speed: 5.6ms preprocess, 501.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 508.2ms\n",
            "Speed: 4.6ms preprocess, 508.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 517.1ms\n",
            "Speed: 8.1ms preprocess, 517.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 517.0ms\n",
            "Speed: 5.8ms preprocess, 517.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.8ms\n",
            "Speed: 3.6ms preprocess, 323.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 317.5ms\n",
            "Speed: 5.1ms preprocess, 317.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 321.3ms\n",
            "Speed: 5.2ms preprocess, 321.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 334.0ms\n",
            "Speed: 3.7ms preprocess, 334.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 325.4ms\n",
            "Speed: 3.5ms preprocess, 325.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 340.3ms\n",
            "Speed: 4.9ms preprocess, 340.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 336.9ms\n",
            "Speed: 4.8ms preprocess, 336.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 324.7ms\n",
            "Speed: 5.7ms preprocess, 324.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 342.2ms\n",
            "Speed: 3.7ms preprocess, 342.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.4ms\n",
            "Speed: 3.7ms preprocess, 331.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 320.2ms\n",
            "Speed: 4.0ms preprocess, 320.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 343.1ms\n",
            "Speed: 3.8ms preprocess, 343.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.1ms\n",
            "Speed: 7.0ms preprocess, 319.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.9ms\n",
            "Speed: 3.8ms preprocess, 319.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.0ms\n",
            "Speed: 5.2ms preprocess, 324.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 317.8ms\n",
            "Speed: 4.4ms preprocess, 317.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.7ms\n",
            "Speed: 4.2ms preprocess, 331.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.7ms\n",
            "Speed: 3.5ms preprocess, 324.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 322.6ms\n",
            "Speed: 3.7ms preprocess, 322.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 342.3ms\n",
            "Speed: 5.1ms preprocess, 342.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4522])\n",
            "data: tensor([[1.1983e+03, 5.7679e+02, 1.3298e+03, 6.1043e+02, 1.9000e+01, 4.5215e-01, 0.0000e+00]])\n",
            "id: tensor([19.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1264.0444,  593.6113,  131.4752,   33.6450]])\n",
            "xywhn: tensor([[0.6584, 0.5496, 0.0685, 0.0312]])\n",
            "xyxy: tensor([[1198.3069,  576.7888, 1329.7821,  610.4338]])\n",
            "xyxyn: tensor([[0.6241, 0.5341, 0.6926, 0.5652]])\n",
            "track_id:  19\n",
            "confidence: tensor(0.4522)\n",
            "formatted plate:  AH1507S\n",
            "buffer:  ['AH1507S']\n",
            "\n",
            "0: 384x640 1 license_plate, 332.0ms\n",
            "Speed: 4.2ms preprocess, 332.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4349])\n",
            "data: tensor([[1.2111e+03, 5.7615e+02, 1.3376e+03, 6.0826e+02, 1.9000e+01, 4.3487e-01, 0.0000e+00]])\n",
            "id: tensor([19.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1274.3694,  592.2069,  126.4596,   32.1094]])\n",
            "xywhn: tensor([[0.6637, 0.5483, 0.0659, 0.0297]])\n",
            "xyxy: tensor([[1211.1395,  576.1522, 1337.5991,  608.2617]])\n",
            "xyxyn: tensor([[0.6308, 0.5335, 0.6967, 0.5632]])\n",
            "track_id:  19\n",
            "confidence: tensor(0.4349)\n",
            "formatted plate:  MH1509S\n",
            "buffer:  ['AH1507S', 'MH1509S']\n",
            "\n",
            "0: 384x640 (no detections), 353.0ms\n",
            "Speed: 3.6ms preprocess, 353.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 328.4ms\n",
            "Speed: 3.7ms preprocess, 328.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4474])\n",
            "data: tensor([[1.2341e+03, 5.7557e+02, 1.3569e+03, 6.0753e+02, 1.9000e+01, 4.4736e-01, 0.0000e+00]])\n",
            "id: tensor([19.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1295.5010,  591.5476,  122.7755,   31.9593]])\n",
            "xywhn: tensor([[0.6747, 0.5477, 0.0639, 0.0296]])\n",
            "xyxy: tensor([[1234.1132,  575.5679, 1356.8887,  607.5272]])\n",
            "xyxyn: tensor([[0.6428, 0.5329, 0.7067, 0.5625]])\n",
            "track_id:  19\n",
            "confidence: tensor(0.4474)\n",
            "formatted plate:  111509S\n",
            "buffer:  ['AH1507S', 'MH1509S', '111509S']\n",
            "Most common:  AH1507S \n",
            "Count:  1\n",
            "\n",
            "0: 384x640 (no detections), 307.9ms\n",
            "Speed: 3.7ms preprocess, 307.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 367.7ms\n",
            "Speed: 5.2ms preprocess, 367.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 498.4ms\n",
            "Speed: 5.7ms preprocess, 498.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 518.2ms\n",
            "Speed: 5.9ms preprocess, 518.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 517.6ms\n",
            "Speed: 5.5ms preprocess, 517.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 498.8ms\n",
            "Speed: 6.0ms preprocess, 498.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 496.8ms\n",
            "Speed: 4.7ms preprocess, 496.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 504.2ms\n",
            "Speed: 6.0ms preprocess, 504.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 514.3ms\n",
            "Speed: 8.2ms preprocess, 514.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 346.2ms\n",
            "Speed: 4.4ms preprocess, 346.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 340.4ms\n",
            "Speed: 4.2ms preprocess, 340.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 329.3ms\n",
            "Speed: 3.6ms preprocess, 329.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 317.5ms\n",
            "Speed: 3.9ms preprocess, 317.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6783])\n",
            "data: tensor([[1.6685e+03, 2.0770e+02, 1.8168e+03, 3.2266e+02, 2.1000e+01, 6.7826e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1742.6409,  265.1827,  148.3767,  114.9555]])\n",
            "xywhn: tensor([[0.9076, 0.2455, 0.0773, 0.1064]])\n",
            "xyxy: tensor([[1668.4525,  207.7050, 1816.8292,  322.6605]])\n",
            "xyxyn: tensor([[0.8690, 0.1923, 0.9463, 0.2988]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.6783)\n",
            "formatted plate:  11077B\n",
            "buffer:  ['11077B']\n",
            "\n",
            "0: 384x640 1 license_plate, 346.9ms\n",
            "Speed: 4.1ms preprocess, 346.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4447])\n",
            "data: tensor([[1.6723e+03, 2.0817e+02, 1.8236e+03, 3.1451e+02, 2.1000e+01, 4.4471e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1747.9424,  261.3424,  151.2191,  106.3401]])\n",
            "xywhn: tensor([[0.9104, 0.2420, 0.0788, 0.0985]])\n",
            "xyxy: tensor([[1672.3328,  208.1724, 1823.5519,  314.5125]])\n",
            "xyxyn: tensor([[0.8710, 0.1928, 0.9498, 0.2912]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.4447)\n",
            "formatted plate:  1T7774\n",
            "buffer:  ['11077B', '1T7774']\n",
            "\n",
            "0: 384x640 1 license_plate, 327.9ms\n",
            "Speed: 3.8ms preprocess, 327.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4554])\n",
            "data: tensor([[1.6790e+03, 2.0856e+02, 1.8356e+03, 3.0736e+02, 2.1000e+01, 4.5539e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1757.3140,  257.9647,  156.5503,   98.8006]])\n",
            "xywhn: tensor([[0.9153, 0.2389, 0.0815, 0.0915]])\n",
            "xyxy: tensor([[1679.0388,  208.5644, 1835.5891,  307.3650]])\n",
            "xyxyn: tensor([[0.8745, 0.1931, 0.9560, 0.2846]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.4554)\n",
            "formatted plate:  14744\n",
            "buffer:  ['11077B', '1T7774', '14744']\n",
            "Most common:  11077B \n",
            "Count:  1\n",
            "\n",
            "0: 384x640 (no detections), 355.5ms\n",
            "Speed: 3.7ms preprocess, 355.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 327.0ms\n",
            "Speed: 5.8ms preprocess, 327.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.7ms\n",
            "Speed: 8.5ms preprocess, 322.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 330.7ms\n",
            "Speed: 4.4ms preprocess, 330.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 307.8ms\n",
            "Speed: 3.4ms preprocess, 307.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.3ms\n",
            "Speed: 4.1ms preprocess, 326.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 325.2ms\n",
            "Speed: 3.6ms preprocess, 325.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 318.1ms\n",
            "Speed: 6.1ms preprocess, 318.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.3ms\n",
            "Speed: 7.6ms preprocess, 331.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.6ms\n",
            "Speed: 4.8ms preprocess, 332.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.6ms\n",
            "Speed: 6.9ms preprocess, 324.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 348.0ms\n",
            "Speed: 4.7ms preprocess, 348.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 335.1ms\n",
            "Speed: 7.7ms preprocess, 335.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 355.1ms\n",
            "Speed: 3.7ms preprocess, 355.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.4ms\n",
            "Speed: 3.6ms preprocess, 324.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 317.1ms\n",
            "Speed: 6.5ms preprocess, 317.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 341.8ms\n",
            "Speed: 3.5ms preprocess, 341.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 328.7ms\n",
            "Speed: 4.1ms preprocess, 328.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.7689])\n",
            "data: tensor([[1.7688e+03, 2.0202e+02, 1.9200e+03, 3.1821e+02, 2.1000e+01, 7.6895e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1844.3792,  260.1163,  151.2417,  116.1963]])\n",
            "xywhn: tensor([[0.9606, 0.2408, 0.0788, 0.1076]])\n",
            "xyxy: tensor([[1768.7583,  202.0182, 1920.0000,  318.2144]])\n",
            "xyxyn: tensor([[0.9212, 0.1871, 1.0000, 0.2946]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.7689)\n",
            "\n",
            "0: 384x640 1 license_plate, 488.5ms\n",
            "Speed: 3.7ms preprocess, 488.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.7607])\n",
            "data: tensor([[1.7716e+03, 2.0059e+02, 1.9200e+03, 3.1946e+02, 2.1000e+01, 7.6068e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1845.8019,  260.0275,  148.3962,  118.8733]])\n",
            "xywhn: tensor([[0.9614, 0.2408, 0.0773, 0.1101]])\n",
            "xyxy: tensor([[1771.6038,  200.5908, 1920.0000,  319.4641]])\n",
            "xyxyn: tensor([[0.9227, 0.1857, 1.0000, 0.2958]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.7607)\n",
            "\n",
            "0: 384x640 (no detections), 501.8ms\n",
            "Speed: 5.0ms preprocess, 501.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 519.6ms\n",
            "Speed: 6.3ms preprocess, 519.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 516.0ms\n",
            "Speed: 6.4ms preprocess, 516.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4191])\n",
            "data: tensor([[4.9056e+02, 5.7656e+02, 5.6670e+02, 6.2104e+02, 2.2000e+01, 4.1906e-01, 0.0000e+00]])\n",
            "id: tensor([22.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[528.6300, 598.7992,  76.1444,  44.4869]])\n",
            "xywhn: tensor([[0.2753, 0.5544, 0.0397, 0.0412]])\n",
            "xyxy: tensor([[490.5578, 576.5558, 566.7022, 621.0427]])\n",
            "xyxyn: tensor([[0.2555, 0.5338, 0.2952, 0.5750]])\n",
            "track_id:  22\n",
            "confidence: tensor(0.4191)\n",
            "formatted plate:  BWR902T\n",
            "buffer:  ['BWR902T']\n",
            "\n",
            "0: 384x640 1 license_plate, 487.4ms\n",
            "Speed: 4.6ms preprocess, 487.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6139])\n",
            "data: tensor([[1.7892e+03, 2.0391e+02, 1.9200e+03, 3.4658e+02, 2.1000e+01, 6.1392e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1854.6030,  275.2445,  130.7939,  142.6636]])\n",
            "xywhn: tensor([[0.9659, 0.2549, 0.0681, 0.1321]])\n",
            "xyxy: tensor([[1789.2061,  203.9127, 1920.0000,  346.5763]])\n",
            "xyxyn: tensor([[0.9319, 0.1888, 1.0000, 0.3209]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.6139)\n",
            "\n",
            "0: 384x640 1 license_plate, 503.8ms\n",
            "Speed: 5.0ms preprocess, 503.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6853])\n",
            "data: tensor([[1.7904e+03, 2.0283e+02, 1.9200e+03, 3.5143e+02, 2.1000e+01, 6.8529e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1855.2073,  277.1266,  129.5854,  148.6013]])\n",
            "xywhn: tensor([[0.9663, 0.2566, 0.0675, 0.1376]])\n",
            "xyxy: tensor([[1790.4146,  202.8259, 1920.0000,  351.4272]])\n",
            "xyxyn: tensor([[0.9325, 0.1878, 1.0000, 0.3254]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.6853)\n",
            "\n",
            "0: 384x640 1 license_plate, 498.9ms\n",
            "Speed: 5.7ms preprocess, 498.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.7213])\n",
            "data: tensor([[1.7937e+03, 2.0262e+02, 1.9198e+03, 3.5384e+02, 2.1000e+01, 7.2129e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1856.7888,  278.2303,  126.1139,  151.2228]])\n",
            "xywhn: tensor([[0.9671, 0.2576, 0.0657, 0.1400]])\n",
            "xyxy: tensor([[1793.7319,  202.6189, 1919.8458,  353.8417]])\n",
            "xyxyn: tensor([[0.9342, 0.1876, 0.9999, 0.3276]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.7213)\n",
            "\n",
            "0: 384x640 1 license_plate, 357.5ms\n",
            "Speed: 5.4ms preprocess, 357.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5673])\n",
            "data: tensor([[1.7961e+03, 1.9745e+02, 1.9191e+03, 3.5872e+02, 2.1000e+01, 5.6728e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1857.5640,  278.0863,  122.9786,  161.2752]])\n",
            "xywhn: tensor([[0.9675, 0.2575, 0.0641, 0.1493]])\n",
            "xyxy: tensor([[1796.0747,  197.4487, 1919.0533,  358.7239]])\n",
            "xyxyn: tensor([[0.9355, 0.1828, 0.9995, 0.3322]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.5673)\n",
            "\n",
            "0: 384x640 2 license_plates, 322.1ms\n",
            "Speed: 3.6ms preprocess, 322.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0., 0.])\n",
            "conf: tensor([0.5347, 0.6631])\n",
            "data: tensor([[1.8006e+03, 1.9535e+02, 1.9192e+03, 3.6330e+02, 2.1000e+01, 5.3467e-01, 0.0000e+00],\n",
            "        [1.8060e+03, 6.8142e+02, 1.9200e+03, 7.7901e+02, 2.3000e+01, 6.6313e-01, 0.0000e+00]])\n",
            "id: tensor([21., 23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([2, 7])\n",
            "xywh: tensor([[1859.8840,  279.3284,  118.6169,  167.9519],\n",
            "        [1863.0249,  730.2166,  113.9503,   97.5946]])\n",
            "xywhn: tensor([[0.9687, 0.2586, 0.0618, 0.1555],\n",
            "        [0.9703, 0.6761, 0.0593, 0.0904]])\n",
            "xyxy: tensor([[1800.5756,  195.3525, 1919.1925,  363.3044],\n",
            "        [1806.0497,  681.4193, 1920.0000,  779.0139]])\n",
            "xyxyn: tensor([[0.9378, 0.1809, 0.9996, 0.3364],\n",
            "        [0.9407, 0.6309, 1.0000, 0.7213]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.5347)\n",
            "track_id:  23\n",
            "confidence: tensor(0.6631)\n",
            "\n",
            "0: 384x640 2 license_plates, 327.1ms\n",
            "Speed: 3.6ms preprocess, 327.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0., 0.])\n",
            "conf: tensor([0.7553, 0.5530])\n",
            "data: tensor([[1.8063e+03, 1.9484e+02, 1.9191e+03, 3.7054e+02, 2.1000e+01, 7.5529e-01, 0.0000e+00],\n",
            "        [1.7747e+03, 6.7829e+02, 1.9200e+03, 7.7115e+02, 2.3000e+01, 5.5297e-01, 0.0000e+00]])\n",
            "id: tensor([21., 23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([2, 7])\n",
            "xywh: tensor([[1862.7351,  282.6888,  112.8275,  175.6951],\n",
            "        [1847.3665,  724.7208,  145.2670,   92.8525]])\n",
            "xywhn: tensor([[0.9702, 0.2617, 0.0588, 0.1627],\n",
            "        [0.9622, 0.6710, 0.0757, 0.0860]])\n",
            "xyxy: tensor([[1806.3213,  194.8413, 1919.1488,  370.5364],\n",
            "        [1774.7330,  678.2945, 1920.0000,  771.1470]])\n",
            "xyxyn: tensor([[0.9408, 0.1804, 0.9996, 0.3431],\n",
            "        [0.9243, 0.6281, 1.0000, 0.7140]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.7553)\n",
            "track_id:  23\n",
            "confidence: tensor(0.5530)\n",
            "\n",
            "0: 384x640 2 license_plates, 344.1ms\n",
            "Speed: 5.2ms preprocess, 344.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0., 0.])\n",
            "conf: tensor([0.7594, 0.7655])\n",
            "data: tensor([[1.8107e+03, 1.9339e+02, 1.9189e+03, 3.7928e+02, 2.1000e+01, 7.5937e-01, 0.0000e+00],\n",
            "        [1.7451e+03, 6.6792e+02, 1.9200e+03, 7.5731e+02, 2.3000e+01, 7.6548e-01, 0.0000e+00]])\n",
            "id: tensor([21., 23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([2, 7])\n",
            "xywh: tensor([[1864.8058,  286.3370,  108.2874,  185.8882],\n",
            "        [1832.5277,  712.6122,  174.9446,   89.3917]])\n",
            "xywhn: tensor([[0.9713, 0.2651, 0.0564, 0.1721],\n",
            "        [0.9544, 0.6598, 0.0911, 0.0828]])\n",
            "xyxy: tensor([[1810.6621,  193.3929, 1918.9495,  379.2811],\n",
            "        [1745.0554,  667.9164, 1920.0000,  757.3080]])\n",
            "xyxyn: tensor([[0.9431, 0.1791, 0.9995, 0.3512],\n",
            "        [0.9089, 0.6184, 1.0000, 0.7012]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.7594)\n",
            "track_id:  23\n",
            "confidence: tensor(0.7655)\n",
            "\n",
            "0: 384x640 2 license_plates, 315.5ms\n",
            "Speed: 4.2ms preprocess, 315.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0., 0.])\n",
            "conf: tensor([0.7175, 0.5532])\n",
            "data: tensor([[1.8144e+03, 1.9317e+02, 1.9189e+03, 3.9027e+02, 2.1000e+01, 7.1750e-01, 0.0000e+00],\n",
            "        [1.7108e+03, 6.5855e+02, 1.8959e+03, 7.4870e+02, 2.3000e+01, 5.5324e-01, 0.0000e+00]])\n",
            "id: tensor([21., 23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([2, 7])\n",
            "xywh: tensor([[1866.6924,  291.7159,  104.4991,  197.0996],\n",
            "        [1803.3596,  703.6257,  185.0450,   90.1536]])\n",
            "xywhn: tensor([[0.9722, 0.2701, 0.0544, 0.1825],\n",
            "        [0.9392, 0.6515, 0.0964, 0.0835]])\n",
            "xyxy: tensor([[1814.4427,  193.1662, 1918.9419,  390.2657],\n",
            "        [1710.8372,  658.5489, 1895.8822,  748.7025]])\n",
            "xyxyn: tensor([[0.9450, 0.1789, 0.9994, 0.3614],\n",
            "        [0.8911, 0.6098, 0.9874, 0.6932]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.7175)\n",
            "track_id:  23\n",
            "confidence: tensor(0.5532)\n",
            "formatted plate:  LL408AJ\n",
            "buffer:  ['LL408AJ']\n",
            "\n",
            "0: 384x640 2 license_plates, 346.7ms\n",
            "Speed: 3.7ms preprocess, 346.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0., 0.])\n",
            "conf: tensor([0.6290, 0.6079])\n",
            "data: tensor([[1.8179e+03, 1.9412e+02, 1.9192e+03, 4.1126e+02, 2.1000e+01, 6.2903e-01, 0.0000e+00],\n",
            "        [1.6788e+03, 6.5555e+02, 1.8639e+03, 7.3934e+02, 2.3000e+01, 6.0794e-01, 0.0000e+00]])\n",
            "id: tensor([21., 23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([2, 7])\n",
            "xywh: tensor([[1868.5374,  302.6897,  101.2540,  217.1308],\n",
            "        [1771.3513,  697.4456,  185.0533,   83.7972]])\n",
            "xywhn: tensor([[0.9732, 0.2803, 0.0527, 0.2010],\n",
            "        [0.9226, 0.6458, 0.0964, 0.0776]])\n",
            "xyxy: tensor([[1817.9104,  194.1243, 1919.1644,  411.2551],\n",
            "        [1678.8246,  655.5470, 1863.8779,  739.3442]])\n",
            "xyxyn: tensor([[0.9468, 0.1797, 0.9996, 0.3808],\n",
            "        [0.8744, 0.6070, 0.9708, 0.6846]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.6290)\n",
            "track_id:  23\n",
            "confidence: tensor(0.6079)\n",
            "formatted plate:  DL408-AJJ\n",
            "buffer:  ['LL408AJ', 'DL408-AJJ']\n",
            "\n",
            "0: 384x640 2 license_plates, 333.5ms\n",
            "Speed: 3.6ms preprocess, 333.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0., 0.])\n",
            "conf: tensor([0.6652, 0.6153])\n",
            "data: tensor([[1.8206e+03, 1.9283e+02, 1.9190e+03, 3.9400e+02, 2.1000e+01, 6.6516e-01, 0.0000e+00],\n",
            "        [1.6472e+03, 6.5168e+02, 1.8309e+03, 7.3176e+02, 2.3000e+01, 6.1533e-01, 0.0000e+00]])\n",
            "id: tensor([21., 23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([2, 7])\n",
            "xywh: tensor([[1869.8101,  293.4138,   98.3384,  201.1757],\n",
            "        [1739.0544,  691.7181,  183.7516,   80.0826]])\n",
            "xywhn: tensor([[0.9739, 0.2717, 0.0512, 0.1863],\n",
            "        [0.9058, 0.6405, 0.0957, 0.0742]])\n",
            "xyxy: tensor([[1820.6409,  192.8260, 1918.9792,  394.0017],\n",
            "        [1647.1787,  651.6768, 1830.9303,  731.7595]])\n",
            "xyxyn: tensor([[0.9483, 0.1785, 0.9995, 0.3648],\n",
            "        [0.8579, 0.6034, 0.9536, 0.6776]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.6652)\n",
            "track_id:  23\n",
            "confidence: tensor(0.6153)\n",
            "formatted plate:  DL408-ABJ\n",
            "buffer:  ['LL408AJ', 'DL408-AJJ', 'DL408-ABJ']\n",
            "Most common:  LL408AJ \n",
            "Count:  1\n",
            "\n",
            "0: 384x640 1 license_plate, 336.1ms\n",
            "Speed: 3.5ms preprocess, 336.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6486])\n",
            "data: tensor([[1.8230e+03, 1.9106e+02, 1.9193e+03, 3.7828e+02, 2.1000e+01, 6.4863e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1871.1404,  284.6690,   96.2626,  187.2258]])\n",
            "xywhn: tensor([[0.9746, 0.2636, 0.0501, 0.1734]])\n",
            "xyxy: tensor([[1823.0092,  191.0562, 1919.2717,  378.2819]])\n",
            "xyxyn: tensor([[0.9495, 0.1769, 0.9996, 0.3503]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.6486)\n",
            "\n",
            "0: 384x640 (no detections), 353.7ms\n",
            "Speed: 5.5ms preprocess, 353.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 347.1ms\n",
            "Speed: 5.4ms preprocess, 347.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4771])\n",
            "data: tensor([[1.5735e+03, 6.3360e+02, 1.7393e+03, 7.0864e+02, 2.3000e+01, 4.7711e-01, 0.0000e+00]])\n",
            "id: tensor([23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1656.4053,  671.1179,  165.8724,   75.0422]])\n",
            "xywhn: tensor([[0.8627, 0.6214, 0.0864, 0.0695]])\n",
            "xyxy: tensor([[1573.4690,  633.5969, 1739.3414,  708.6390]])\n",
            "xyxyn: tensor([[0.8195, 0.5867, 0.9059, 0.6561]])\n",
            "track_id:  23\n",
            "confidence: tensor(0.4771)\n",
            "formatted plate:  DL408AB\n",
            "buffer:  ['LL408AJ', 'DL408-AJJ', 'DL408-ABJ', 'DL408AB']\n",
            "Most common:  LL408AJ \n",
            "Count:  1\n",
            "\n",
            "0: 384x640 1 license_plate, 348.4ms\n",
            "Speed: 3.7ms preprocess, 348.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6724])\n",
            "data: tensor([[1.5522e+03, 6.3215e+02, 1.7084e+03, 7.0336e+02, 2.3000e+01, 6.7236e-01, 0.0000e+00]])\n",
            "id: tensor([23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1630.3076,  667.7562,  156.1405,   71.2165]])\n",
            "xywhn: tensor([[0.8491, 0.6183, 0.0813, 0.0659]])\n",
            "xyxy: tensor([[1552.2373,  632.1479, 1708.3778,  703.3644]])\n",
            "xyxyn: tensor([[0.8085, 0.5853, 0.8898, 0.6513]])\n",
            "track_id:  23\n",
            "confidence: tensor(0.6724)\n",
            "formatted plate:  DL408-ABJ\n",
            "buffer:  ['LL408AJ', 'DL408-AJJ', 'DL408-ABJ', 'DL408AB', 'DL408-ABJ']\n",
            "Most common:  DL408-ABJ \n",
            "Count:  2\n",
            "\n",
            "0: 384x640 2 license_plates, 326.8ms\n",
            "Speed: 3.5ms preprocess, 326.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0., 0.])\n",
            "conf: tensor([0.5574, 0.4489])\n",
            "data: tensor([[1.5339e+03, 6.2737e+02, 1.6841e+03, 6.9749e+02, 2.3000e+01, 5.5736e-01, 0.0000e+00],\n",
            "        [1.8322e+03, 1.8670e+02, 1.9200e+03, 3.7694e+02, 2.1000e+01, 4.4893e-01, 0.0000e+00]])\n",
            "id: tensor([23., 21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([2, 7])\n",
            "xywh: tensor([[1608.9976,  662.4278,  150.2921,   70.1218],\n",
            "        [1876.0942,  281.8201,   87.8116,  190.2360]])\n",
            "xywhn: tensor([[0.8380, 0.6134, 0.0783, 0.0649],\n",
            "        [0.9771, 0.2609, 0.0457, 0.1761]])\n",
            "xyxy: tensor([[1533.8516,  627.3669, 1684.1437,  697.4887],\n",
            "        [1832.1884,  186.7021, 1920.0000,  376.9381]])\n",
            "xyxyn: tensor([[0.7989, 0.5809, 0.8772, 0.6458],\n",
            "        [0.9543, 0.1729, 1.0000, 0.3490]])\n",
            "track_id:  23\n",
            "confidence: tensor(0.5574)\n",
            "formatted plate:  DL408-ABJ\n",
            "buffer:  ['LL408AJ', 'DL408-AJJ', 'DL408-ABJ', 'DL408AB', 'DL408-ABJ', 'DL408-ABJ']\n",
            "Most common:  DL408-ABJ \n",
            "Count:  3\n",
            "track_id:  21\n",
            "confidence: tensor(0.4489)\n",
            "\n",
            "0: 384x640 1 license_plate, 336.9ms\n",
            "Speed: 3.6ms preprocess, 336.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5619])\n",
            "data: tensor([[1.5133e+03, 6.2458e+02, 1.6625e+03, 6.9179e+02, 2.3000e+01, 5.6190e-01, 0.0000e+00]])\n",
            "id: tensor([23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1587.8871,  658.1857,  149.2314,   67.2047]])\n",
            "xywhn: tensor([[0.8270, 0.6094, 0.0777, 0.0622]])\n",
            "xyxy: tensor([[1513.2714,  624.5834, 1662.5028,  691.7881]])\n",
            "xyxyn: tensor([[0.7882, 0.5783, 0.8659, 0.6405]])\n",
            "track_id:  23\n",
            "confidence: tensor(0.5619)\n",
            "formatted plate:  DL408-ABJ\n",
            "buffer:  ['LL408AJ', 'DL408-AJJ', 'DL408-ABJ', 'DL408AB', 'DL408-ABJ', 'DL408-ABJ', 'DL408-ABJ']\n",
            "Most common:  DL408-ABJ \n",
            "Count:  4\n",
            "\n",
            "0: 384x640 1 license_plate, 360.3ms\n",
            "Speed: 3.5ms preprocess, 360.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4710])\n",
            "data: tensor([[1.4968e+03, 6.1809e+02, 1.6408e+03, 6.8631e+02, 2.3000e+01, 4.7100e-01, 0.0000e+00]])\n",
            "id: tensor([23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1568.8110,  652.1982,  144.0461,   68.2260]])\n",
            "xywhn: tensor([[0.8171, 0.6039, 0.0750, 0.0632]])\n",
            "xyxy: tensor([[1496.7880,  618.0852, 1640.8341,  686.3112]])\n",
            "xyxyn: tensor([[0.7796, 0.5723, 0.8546, 0.6355]])\n",
            "track_id:  23\n",
            "confidence: tensor(0.4710)\n",
            "formatted plate:  DL408-ABJ\n",
            "buffer:  ['LL408AJ', 'DL408-AJJ', 'DL408-ABJ', 'DL408AB', 'DL408-ABJ', 'DL408-ABJ', 'DL408-ABJ', 'DL408-ABJ']\n",
            "Most common:  DL408-ABJ \n",
            "Count:  5\n",
            "\n",
            "0: 384x640 (no detections), 333.8ms\n",
            "Speed: 3.6ms preprocess, 333.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 341.0ms\n",
            "Speed: 4.0ms preprocess, 341.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 314.3ms\n",
            "Speed: 4.6ms preprocess, 314.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5495])\n",
            "data: tensor([[1.4470e+03, 6.0539e+02, 1.5851e+03, 6.6931e+02, 2.3000e+01, 5.4954e-01, 0.0000e+00]])\n",
            "id: tensor([23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1516.0160,  637.3470,  138.0688,   63.9163]])\n",
            "xywhn: tensor([[0.7896, 0.5901, 0.0719, 0.0592]])\n",
            "xyxy: tensor([[1446.9816,  605.3889, 1585.0504,  669.3052]])\n",
            "xyxyn: tensor([[0.7536, 0.5605, 0.8255, 0.6197]])\n",
            "track_id:  23\n",
            "confidence: tensor(0.5495)\n",
            "formatted plate:  DL408AB\n",
            "buffer:  ['LL408AJ', 'DL408-AJJ', 'DL408-ABJ', 'DL408AB', 'DL408-ABJ', 'DL408-ABJ', 'DL408-ABJ', 'DL408-ABJ', 'DL408AB']\n",
            "Most common:  DL408-ABJ \n",
            "Count:  5\n",
            "\n",
            "0: 384x640 1 license_plate, 332.5ms\n",
            "Speed: 4.8ms preprocess, 332.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5970])\n",
            "data: tensor([[1.4312e+03, 6.0289e+02, 1.5672e+03, 6.6588e+02, 2.3000e+01, 5.9698e-01, 0.0000e+00]])\n",
            "id: tensor([23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1499.2117,  634.3826,  135.9380,   62.9913]])\n",
            "xywhn: tensor([[0.7808, 0.5874, 0.0708, 0.0583]])\n",
            "xyxy: tensor([[1431.2427,  602.8870, 1567.1807,  665.8782]])\n",
            "xyxyn: tensor([[0.7454, 0.5582, 0.8162, 0.6166]])\n",
            "track_id:  23\n",
            "confidence: tensor(0.5970)\n",
            "formatted plate:  DL408AB\n",
            "buffer:  ['LL408AJ', 'DL408-AJJ', 'DL408-ABJ', 'DL408AB', 'DL408-ABJ', 'DL408-ABJ', 'DL408-ABJ', 'DL408-ABJ', 'DL408AB', 'DL408AB']\n",
            "Most common:  DL408-ABJ \n",
            "Count:  5\n",
            "\n",
            "0: 384x640 (no detections), 344.8ms\n",
            "Speed: 5.5ms preprocess, 344.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 327.0ms\n",
            "Speed: 3.6ms preprocess, 327.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 337.0ms\n",
            "Speed: 6.5ms preprocess, 337.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4148])\n",
            "data: tensor([[1.3930e+03, 5.9585e+02, 1.5223e+03, 6.5589e+02, 2.3000e+01, 4.1479e-01, 0.0000e+00]])\n",
            "id: tensor([23.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1457.6638,  625.8739,  129.3567,   60.0399]])\n",
            "xywhn: tensor([[0.7592, 0.5795, 0.0674, 0.0556]])\n",
            "xyxy: tensor([[1392.9855,  595.8540, 1522.3422,  655.8939]])\n",
            "xyxyn: tensor([[0.7255, 0.5517, 0.7929, 0.6073]])\n",
            "track_id:  23\n",
            "confidence: tensor(0.4148)\n",
            "formatted plate:  DL408A8\n",
            "buffer:  ['LL408AJ', 'DL408-AJJ', 'DL408-ABJ', 'DL408AB', 'DL408-ABJ', 'DL408-ABJ', 'DL408-ABJ', 'DL408-ABJ', 'DL408AB', 'DL408AB', 'DL408A8']\n",
            "Most common:  DL408-ABJ \n",
            "Count:  5\n",
            "\n",
            "0: 384x640 1 license_plate, 331.7ms\n",
            "Speed: 3.6ms preprocess, 331.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6450])\n",
            "data: tensor([[1.8411e+03, 1.8607e+02, 1.9190e+03, 3.6819e+02, 2.1000e+01, 6.4501e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1880.0537,  277.1279,   77.9717,  182.1182]])\n",
            "xywhn: tensor([[0.9792, 0.2566, 0.0406, 0.1686]])\n",
            "xyxy: tensor([[1841.0679,  186.0688, 1919.0396,  368.1870]])\n",
            "xyxyn: tensor([[0.9589, 0.1723, 0.9995, 0.3409]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.6450)\n",
            "\n",
            "0: 384x640 2 license_plates, 329.8ms\n",
            "Speed: 3.6ms preprocess, 329.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0., 0.])\n",
            "conf: tensor([0.6582, 0.4021])\n",
            "data: tensor([[1.8424e+03, 1.8574e+02, 1.9191e+03, 3.6779e+02, 2.1000e+01, 6.5822e-01, 0.0000e+00],\n",
            "        [5.3768e+02, 5.7364e+02, 6.3070e+02, 6.1713e+02, 2.2000e+01, 4.0208e-01, 0.0000e+00]])\n",
            "id: tensor([21., 22.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([2, 7])\n",
            "xywh: tensor([[1880.7627,  276.7674,   76.6349,  182.0521],\n",
            "        [ 584.1860,  595.3851,   93.0203,   43.4820]])\n",
            "xywhn: tensor([[0.9796, 0.2563, 0.0399, 0.1686],\n",
            "        [0.3043, 0.5513, 0.0484, 0.0403]])\n",
            "xyxy: tensor([[1842.4453,  185.7414, 1919.0802,  367.7935],\n",
            "        [ 537.6759,  573.6441,  630.6962,  617.1261]])\n",
            "xyxyn: tensor([[0.9596, 0.1720, 0.9995, 0.3405],\n",
            "        [0.2800, 0.5312, 0.3285, 0.5714]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.6582)\n",
            "track_id:  22\n",
            "confidence: tensor(0.4021)\n",
            "formatted plate:  BWR-902TT\n",
            "buffer:  ['BWR902T', 'BWR-902TT']\n",
            "\n",
            "0: 384x640 1 license_plate, 457.3ms\n",
            "Speed: 19.4ms preprocess, 457.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6592])\n",
            "data: tensor([[1.8450e+03, 1.8503e+02, 1.9191e+03, 3.6675e+02, 2.1000e+01, 6.5920e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1882.0542,  275.8878,   74.1473,  181.7212]])\n",
            "xywhn: tensor([[0.9802, 0.2555, 0.0386, 0.1683]])\n",
            "xyxy: tensor([[1844.9805,  185.0271, 1919.1278,  366.7484]])\n",
            "xyxyn: tensor([[0.9609, 0.1713, 0.9995, 0.3396]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.6592)\n",
            "\n",
            "0: 384x640 1 license_plate, 973.2ms\n",
            "Speed: 5.7ms preprocess, 973.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5937])\n",
            "data: tensor([[1.8459e+03, 1.8483e+02, 1.9192e+03, 3.7598e+02, 2.1000e+01, 5.9371e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1882.5239,  280.4052,   73.3448,  191.1511]])\n",
            "xywhn: tensor([[0.9805, 0.2596, 0.0382, 0.1770]])\n",
            "xyxy: tensor([[1845.8516,  184.8297, 1919.1964,  375.9808]])\n",
            "xyxyn: tensor([[0.9614, 0.1711, 0.9996, 0.3481]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.5937)\n",
            "\n",
            "0: 384x640 1 license_plate, 504.5ms\n",
            "Speed: 14.1ms preprocess, 504.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5659])\n",
            "data: tensor([[1.8468e+03, 1.8261e+02, 1.9193e+03, 4.7498e+02, 2.1000e+01, 5.6591e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1883.0596,  328.7939,   72.4906,  292.3723]])\n",
            "xywhn: tensor([[0.9808, 0.3044, 0.0378, 0.2707]])\n",
            "xyxy: tensor([[1846.8142,  182.6078, 1919.3048,  474.9801]])\n",
            "xyxyn: tensor([[0.9619, 0.1691, 0.9996, 0.4398]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.5659)\n",
            "\n",
            "0: 384x640 1 license_plate, 496.9ms\n",
            "Speed: 8.4ms preprocess, 496.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5727])\n",
            "data: tensor([[1.8481e+03, 1.8168e+02, 1.9193e+03, 4.3370e+02, 2.1000e+01, 5.7270e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1883.7275,  307.6871,   71.2061,  252.0160]])\n",
            "xywhn: tensor([[0.9811, 0.2849, 0.0371, 0.2333]])\n",
            "xyxy: tensor([[1848.1245,  181.6791, 1919.3306,  433.6951]])\n",
            "xyxyn: tensor([[0.9626, 0.1682, 0.9997, 0.4016]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.5727)\n",
            "\n",
            "0: 384x640 1 license_plate, 514.9ms\n",
            "Speed: 7.4ms preprocess, 514.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5334])\n",
            "data: tensor([[1.8507e+03, 1.8112e+02, 1.9193e+03, 4.1001e+02, 2.1000e+01, 5.3345e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1885.0089,  295.5644,   68.6655,  228.8861]])\n",
            "xywhn: tensor([[0.9818, 0.2737, 0.0358, 0.2119]])\n",
            "xyxy: tensor([[1850.6761,  181.1214, 1919.3417,  410.0075]])\n",
            "xyxyn: tensor([[0.9639, 0.1677, 0.9997, 0.3796]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.5334)\n",
            "\n",
            "0: 384x640 1 license_plate, 526.4ms\n",
            "Speed: 8.2ms preprocess, 526.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4417])\n",
            "data: tensor([[1.8524e+03, 1.8074e+02, 1.9194e+03, 5.0057e+02, 2.1000e+01, 4.4170e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1885.9260,  340.6551,   67.0343,  319.8391]])\n",
            "xywhn: tensor([[0.9823, 0.3154, 0.0349, 0.2961]])\n",
            "xyxy: tensor([[1852.4088,  180.7355, 1919.4431,  500.5746]])\n",
            "xyxyn: tensor([[0.9648, 0.1673, 0.9997, 0.4635]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.4417)\n",
            "\n",
            "0: 384x640 1 license_plate, 533.9ms\n",
            "Speed: 4.0ms preprocess, 533.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4509])\n",
            "data: tensor([[1.8536e+03, 1.8061e+02, 1.9194e+03, 5.1674e+02, 2.1000e+01, 4.5094e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1886.5027,  348.6758,   65.7301,  336.1232]])\n",
            "xywhn: tensor([[0.9826, 0.3228, 0.0342, 0.3112]])\n",
            "xyxy: tensor([[1853.6377,  180.6142, 1919.3678,  516.7374]])\n",
            "xyxyn: tensor([[0.9654, 0.1672, 0.9997, 0.4785]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.4509)\n",
            "\n",
            "0: 384x640 1 license_plate, 333.2ms\n",
            "Speed: 7.7ms preprocess, 333.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4606])\n",
            "data: tensor([[1.8550e+03, 1.7995e+02, 1.9193e+03, 4.5692e+02, 2.1000e+01, 4.6062e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1887.1604,  318.4336,   64.2266,  276.9698]])\n",
            "xywhn: tensor([[0.9829, 0.2948, 0.0335, 0.2565]])\n",
            "xyxy: tensor([[1855.0471,  179.9487, 1919.2737,  456.9185]])\n",
            "xyxyn: tensor([[0.9662, 0.1666, 0.9996, 0.4231]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.4606)\n",
            "\n",
            "0: 384x640 1 license_plate, 367.6ms\n",
            "Speed: 4.5ms preprocess, 367.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4786])\n",
            "data: tensor([[1.8557e+03, 1.7981e+02, 1.9193e+03, 4.8380e+02, 2.1000e+01, 4.7863e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1887.5383,  331.8022,   63.5779,  303.9872]])\n",
            "xywhn: tensor([[0.9831, 0.3072, 0.0331, 0.2815]])\n",
            "xyxy: tensor([[1855.7494,  179.8086, 1919.3273,  483.7958]])\n",
            "xyxyn: tensor([[0.9665, 0.1665, 0.9996, 0.4480]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.4786)\n",
            "\n",
            "0: 384x640 1 license_plate, 330.3ms\n",
            "Speed: 4.3ms preprocess, 330.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4910])\n",
            "data: tensor([[1.8568e+03, 1.7920e+02, 1.9192e+03, 4.7953e+02, 2.1000e+01, 4.9101e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1888.0239,  329.3625,   62.4410,  300.3312]])\n",
            "xywhn: tensor([[0.9833, 0.3050, 0.0325, 0.2781]])\n",
            "xyxy: tensor([[1856.8035,  179.1969, 1919.2445,  479.5282]])\n",
            "xyxyn: tensor([[0.9671, 0.1659, 0.9996, 0.4440]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.4910)\n",
            "\n",
            "0: 384x640 1 license_plate, 328.5ms\n",
            "Speed: 3.6ms preprocess, 328.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4622])\n",
            "data: tensor([[1.8570e+03, 1.7947e+02, 1.9194e+03, 4.8992e+02, 2.1000e+01, 4.6217e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1888.2007,  334.6935,   62.4912,  310.4545]])\n",
            "xywhn: tensor([[0.9834, 0.3099, 0.0325, 0.2875]])\n",
            "xyxy: tensor([[1856.9551,  179.4663, 1919.4463,  489.9207]])\n",
            "xyxyn: tensor([[0.9672, 0.1662, 0.9997, 0.4536]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.4622)\n",
            "\n",
            "0: 384x640 1 license_plate, 324.6ms\n",
            "Speed: 3.5ms preprocess, 324.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4678])\n",
            "data: tensor([[1.8575e+03, 1.7925e+02, 1.9194e+03, 5.0631e+02, 2.1000e+01, 4.6776e-01, 0.0000e+00]])\n",
            "id: tensor([21.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1888.4777,  342.7762,   61.9241,  327.0611]])\n",
            "xywhn: tensor([[0.9836, 0.3174, 0.0323, 0.3028]])\n",
            "xyxy: tensor([[1857.5156,  179.2457, 1919.4397,  506.3068]])\n",
            "xyxyn: tensor([[0.9675, 0.1660, 0.9997, 0.4688]])\n",
            "track_id:  21\n",
            "confidence: tensor(0.4678)\n",
            "\n",
            "0: 384x640 (no detections), 314.8ms\n",
            "Speed: 3.5ms preprocess, 314.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 342.3ms\n",
            "Speed: 4.4ms preprocess, 342.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.9ms\n",
            "Speed: 4.4ms preprocess, 324.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 320.0ms\n",
            "Speed: 4.6ms preprocess, 320.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 339.1ms\n",
            "Speed: 4.5ms preprocess, 339.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 337.2ms\n",
            "Speed: 4.2ms preprocess, 337.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 331.0ms\n",
            "Speed: 6.0ms preprocess, 331.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 310.0ms\n",
            "Speed: 3.5ms preprocess, 310.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 312.9ms\n",
            "Speed: 3.6ms preprocess, 312.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 329.0ms\n",
            "Speed: 4.1ms preprocess, 329.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.8ms\n",
            "Speed: 3.5ms preprocess, 331.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 328.1ms\n",
            "Speed: 3.8ms preprocess, 328.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 330.5ms\n",
            "Speed: 6.7ms preprocess, 330.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 325.8ms\n",
            "Speed: 3.7ms preprocess, 325.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 338.4ms\n",
            "Speed: 6.1ms preprocess, 338.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 318.2ms\n",
            "Speed: 6.9ms preprocess, 318.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.6ms\n",
            "Speed: 6.8ms preprocess, 324.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.7ms\n",
            "Speed: 5.8ms preprocess, 331.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 327.3ms\n",
            "Speed: 3.6ms preprocess, 327.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 400.9ms\n",
            "Speed: 6.3ms preprocess, 400.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 522.2ms\n",
            "Speed: 3.8ms preprocess, 522.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 502.6ms\n",
            "Speed: 9.0ms preprocess, 502.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 504.0ms\n",
            "Speed: 6.0ms preprocess, 504.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 500.3ms\n",
            "Speed: 5.7ms preprocess, 500.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 495.6ms\n",
            "Speed: 3.6ms preprocess, 495.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 501.4ms\n",
            "Speed: 3.7ms preprocess, 501.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 487.4ms\n",
            "Speed: 7.2ms preprocess, 487.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.1ms\n",
            "Speed: 4.4ms preprocess, 326.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 321.8ms\n",
            "Speed: 3.6ms preprocess, 321.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 336.2ms\n",
            "Speed: 6.8ms preprocess, 336.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.5ms\n",
            "Speed: 4.1ms preprocess, 322.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.7ms\n",
            "Speed: 3.7ms preprocess, 319.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 343.0ms\n",
            "Speed: 5.1ms preprocess, 343.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.9ms\n",
            "Speed: 3.6ms preprocess, 323.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.4ms\n",
            "Speed: 3.7ms preprocess, 332.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 312.7ms\n",
            "Speed: 3.7ms preprocess, 312.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 333.1ms\n",
            "Speed: 3.7ms preprocess, 333.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 356.1ms\n",
            "Speed: 4.3ms preprocess, 356.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.1ms\n",
            "Speed: 3.6ms preprocess, 332.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 348.8ms\n",
            "Speed: 3.6ms preprocess, 348.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.4ms\n",
            "Speed: 8.2ms preprocess, 332.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.5ms\n",
            "Speed: 3.6ms preprocess, 322.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 347.2ms\n",
            "Speed: 5.7ms preprocess, 347.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 333.4ms\n",
            "Speed: 5.8ms preprocess, 333.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 330.0ms\n",
            "Speed: 5.5ms preprocess, 330.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 328.5ms\n",
            "Speed: 8.4ms preprocess, 328.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 318.3ms\n",
            "Speed: 3.6ms preprocess, 318.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 334.7ms\n",
            "Speed: 3.7ms preprocess, 334.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 325.2ms\n",
            "Speed: 3.5ms preprocess, 325.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 312.9ms\n",
            "Speed: 4.1ms preprocess, 312.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 361.8ms\n",
            "Speed: 6.1ms preprocess, 361.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 421.0ms\n",
            "Speed: 3.7ms preprocess, 421.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 497.8ms\n",
            "Speed: 4.0ms preprocess, 497.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 495.3ms\n",
            "Speed: 6.6ms preprocess, 495.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 522.6ms\n",
            "Speed: 5.2ms preprocess, 522.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 510.2ms\n",
            "Speed: 6.6ms preprocess, 510.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 488.7ms\n",
            "Speed: 7.9ms preprocess, 488.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 511.9ms\n",
            "Speed: 6.5ms preprocess, 511.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 446.7ms\n",
            "Speed: 5.4ms preprocess, 446.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 337.4ms\n",
            "Speed: 3.6ms preprocess, 337.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 320.2ms\n",
            "Speed: 4.1ms preprocess, 320.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.6ms\n",
            "Speed: 3.6ms preprocess, 332.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.7ms\n",
            "Speed: 4.0ms preprocess, 331.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 346.4ms\n",
            "Speed: 6.6ms preprocess, 346.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 362.4ms\n",
            "Speed: 3.8ms preprocess, 362.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.2ms\n",
            "Speed: 4.3ms preprocess, 332.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 320.0ms\n",
            "Speed: 7.1ms preprocess, 320.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 350.1ms\n",
            "Speed: 5.7ms preprocess, 350.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.1ms\n",
            "Speed: 3.6ms preprocess, 324.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.4ms\n",
            "Speed: 3.5ms preprocess, 319.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 314.8ms\n",
            "Speed: 5.5ms preprocess, 314.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.6ms\n",
            "Speed: 5.6ms preprocess, 323.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 343.0ms\n",
            "Speed: 3.5ms preprocess, 343.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.3ms\n",
            "Speed: 3.7ms preprocess, 326.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.0ms\n",
            "Speed: 3.6ms preprocess, 326.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.8ms\n",
            "Speed: 4.3ms preprocess, 332.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 321.5ms\n",
            "Speed: 4.1ms preprocess, 321.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 license_plate, 335.8ms\n",
            "Speed: 6.6ms preprocess, 335.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5987])\n",
            "data: tensor([[1.8483e+03, 5.9379e+02, 1.9195e+03, 6.5905e+02, 2.9000e+01, 5.9868e-01, 0.0000e+00]])\n",
            "id: tensor([29.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1883.8860,  626.4152,   71.1702,   65.2601]])\n",
            "xywhn: tensor([[0.9812, 0.5800, 0.0371, 0.0604]])\n",
            "xyxy: tensor([[1848.3009,  593.7852, 1919.4711,  659.0452]])\n",
            "xyxyn: tensor([[0.9627, 0.5498, 0.9997, 0.6102]])\n",
            "track_id:  29\n",
            "confidence: tensor(0.5987)\n",
            "\n",
            "0: 384x640 1 license_plate, 326.2ms\n",
            "Speed: 6.1ms preprocess, 326.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4323])\n",
            "data: tensor([[1.8383e+03, 5.9745e+02, 1.9200e+03, 6.5228e+02, 2.9000e+01, 4.3226e-01, 0.0000e+00]])\n",
            "id: tensor([29.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1879.1658,  624.8649,   81.6517,   54.8207]])\n",
            "xywhn: tensor([[0.9787, 0.5786, 0.0425, 0.0508]])\n",
            "xyxy: tensor([[1838.3398,  597.4545, 1919.9916,  652.2752]])\n",
            "xyxyn: tensor([[0.9575, 0.5532, 1.0000, 0.6040]])\n",
            "track_id:  29\n",
            "confidence: tensor(0.4323)\n",
            "\n",
            "0: 384x640 1 license_plate, 316.1ms\n",
            "Speed: 3.6ms preprocess, 316.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.4704])\n",
            "data: tensor([[1.8160e+03, 5.8824e+02, 1.9200e+03, 6.4606e+02, 2.9000e+01, 4.7042e-01, 0.0000e+00]])\n",
            "id: tensor([29.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1867.9946,  617.1492,  104.0107,   57.8242]])\n",
            "xywhn: tensor([[0.9729, 0.5714, 0.0542, 0.0535]])\n",
            "xyxy: tensor([[1815.9893,  588.2371, 1920.0000,  646.0612]])\n",
            "xyxyn: tensor([[0.9458, 0.5447, 1.0000, 0.5982]])\n",
            "track_id:  29\n",
            "confidence: tensor(0.4704)\n",
            "\n",
            "0: 384x640 1 license_plate, 335.8ms\n",
            "Speed: 3.6ms preprocess, 335.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6465])\n",
            "data: tensor([[1.8021e+03, 5.8210e+02, 1.9200e+03, 6.4142e+02, 2.9000e+01, 6.4650e-01, 0.0000e+00]])\n",
            "id: tensor([29.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1861.0601,  611.7639,  117.8799,   59.3203]])\n",
            "xywhn: tensor([[0.9693, 0.5664, 0.0614, 0.0549]])\n",
            "xyxy: tensor([[1802.1201,  582.1038, 1920.0000,  641.4241]])\n",
            "xyxyn: tensor([[0.9386, 0.5390, 1.0000, 0.5939]])\n",
            "track_id:  29\n",
            "confidence: tensor(0.6465)\n",
            "\n",
            "0: 384x640 1 license_plate, 326.5ms\n",
            "Speed: 3.8ms preprocess, 326.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6462])\n",
            "data: tensor([[1.7851e+03, 5.8065e+02, 1.9200e+03, 6.4272e+02, 2.9000e+01, 6.4620e-01, 0.0000e+00]])\n",
            "id: tensor([29.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1852.5505,  611.6863,  134.8988,   62.0648]])\n",
            "xywhn: tensor([[0.9649, 0.5664, 0.0703, 0.0575]])\n",
            "xyxy: tensor([[1785.1012,  580.6539, 1920.0000,  642.7187]])\n",
            "xyxyn: tensor([[0.9297, 0.5376, 1.0000, 0.5951]])\n",
            "track_id:  29\n",
            "confidence: tensor(0.6462)\n",
            "\n",
            "0: 384x640 1 license_plate, 328.0ms\n",
            "Speed: 3.7ms preprocess, 328.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.6214])\n",
            "data: tensor([[1.7687e+03, 5.8041e+02, 1.9183e+03, 6.3847e+02, 2.9000e+01, 6.2139e-01, 0.0000e+00]])\n",
            "id: tensor([29.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1843.5168,  609.4423,  149.6281,   58.0555]])\n",
            "xywhn: tensor([[0.9602, 0.5643, 0.0779, 0.0538]])\n",
            "xyxy: tensor([[1768.7029,  580.4146, 1918.3309,  638.4701]])\n",
            "xyxyn: tensor([[0.9212, 0.5374, 0.9991, 0.5912]])\n",
            "track_id:  29\n",
            "confidence: tensor(0.6214)\n",
            "\n",
            "0: 384x640 1 license_plate, 437.1ms\n",
            "Speed: 6.2ms preprocess, 437.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5511])\n",
            "data: tensor([[1.7528e+03, 5.7872e+02, 1.9193e+03, 6.3593e+02, 2.9000e+01, 5.5106e-01, 0.0000e+00]])\n",
            "id: tensor([29.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1836.0505,  607.3234,  166.4965,   57.2062]])\n",
            "xywhn: tensor([[0.9563, 0.5623, 0.0867, 0.0530]])\n",
            "xyxy: tensor([[1752.8022,  578.7203, 1919.2987,  635.9265]])\n",
            "xyxyn: tensor([[0.9129, 0.5359, 0.9996, 0.5888]])\n",
            "track_id:  29\n",
            "confidence: tensor(0.5511)\n",
            "\n",
            "0: 384x640 1 license_plate, 510.1ms\n",
            "Speed: 6.4ms preprocess, 510.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "boxes: ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([0.])\n",
            "conf: tensor([0.5142])\n",
            "data: tensor([[1.7491e+03, 5.7874e+02, 1.9182e+03, 6.3507e+02, 2.9000e+01, 5.1425e-01, 0.0000e+00]])\n",
            "id: tensor([29.])\n",
            "is_track: True\n",
            "orig_shape: (1080, 1920)\n",
            "shape: torch.Size([1, 7])\n",
            "xywh: tensor([[1833.6089,  606.9033,  169.0999,   56.3334]])\n",
            "xywhn: tensor([[0.9550, 0.5619, 0.0881, 0.0522]])\n",
            "xyxy: tensor([[1749.0590,  578.7366, 1918.1588,  635.0700]])\n",
            "xyxyn: tensor([[0.9110, 0.5359, 0.9990, 0.5880]])\n",
            "track_id:  29\n",
            "confidence: tensor(0.5142)\n",
            "\n",
            "0: 384x640 (no detections), 490.6ms\n",
            "Speed: 7.5ms preprocess, 490.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 532.3ms\n",
            "Speed: 5.0ms preprocess, 532.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 492.7ms\n",
            "Speed: 5.1ms preprocess, 492.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 502.7ms\n",
            "Speed: 7.7ms preprocess, 502.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 498.4ms\n",
            "Speed: 7.9ms preprocess, 498.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 393.2ms\n",
            "Speed: 5.6ms preprocess, 393.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 318.4ms\n",
            "Speed: 4.7ms preprocess, 318.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 345.4ms\n",
            "Speed: 9.3ms preprocess, 345.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 318.0ms\n",
            "Speed: 3.5ms preprocess, 318.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.9ms\n",
            "Speed: 4.2ms preprocess, 326.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 340.5ms\n",
            "Speed: 4.2ms preprocess, 340.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 317.4ms\n",
            "Speed: 6.0ms preprocess, 317.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 346.6ms\n",
            "Speed: 3.5ms preprocess, 346.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 325.3ms\n",
            "Speed: 4.1ms preprocess, 325.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.0ms\n",
            "Speed: 7.0ms preprocess, 332.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 335.7ms\n",
            "Speed: 7.1ms preprocess, 335.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 329.3ms\n",
            "Speed: 3.9ms preprocess, 329.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.6ms\n",
            "Speed: 8.8ms preprocess, 331.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 315.6ms\n",
            "Speed: 7.7ms preprocess, 315.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.0ms\n",
            "Speed: 3.6ms preprocess, 324.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 338.5ms\n",
            "Speed: 7.0ms preprocess, 338.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 318.5ms\n",
            "Speed: 8.0ms preprocess, 318.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.5ms\n",
            "Speed: 7.4ms preprocess, 323.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.3ms\n",
            "Speed: 3.5ms preprocess, 326.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 318.1ms\n",
            "Speed: 4.6ms preprocess, 318.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 327.8ms\n",
            "Speed: 3.6ms preprocess, 327.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 321.7ms\n",
            "Speed: 3.5ms preprocess, 321.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.6ms\n",
            "Speed: 4.2ms preprocess, 326.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 333.8ms\n",
            "Speed: 3.5ms preprocess, 333.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.1ms\n",
            "Speed: 3.5ms preprocess, 323.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 466.3ms\n",
            "Speed: 5.8ms preprocess, 466.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 505.1ms\n",
            "Speed: 10.8ms preprocess, 505.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 504.8ms\n",
            "Speed: 3.5ms preprocess, 504.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 504.0ms\n",
            "Speed: 7.7ms preprocess, 504.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 522.2ms\n",
            "Speed: 10.3ms preprocess, 522.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 511.5ms\n",
            "Speed: 8.5ms preprocess, 511.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 514.3ms\n",
            "Speed: 7.7ms preprocess, 514.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 392.0ms\n",
            "Speed: 6.1ms preprocess, 392.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 334.9ms\n",
            "Speed: 6.7ms preprocess, 334.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 316.3ms\n",
            "Speed: 5.6ms preprocess, 316.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 334.4ms\n",
            "Speed: 5.9ms preprocess, 334.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 321.0ms\n",
            "Speed: 3.6ms preprocess, 321.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 315.9ms\n",
            "Speed: 4.2ms preprocess, 315.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 356.7ms\n",
            "Speed: 5.8ms preprocess, 356.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.4ms\n",
            "Speed: 4.2ms preprocess, 323.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.1ms\n",
            "Speed: 5.4ms preprocess, 323.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 345.7ms\n",
            "Speed: 5.5ms preprocess, 345.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.6ms\n",
            "Speed: 3.7ms preprocess, 326.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 345.9ms\n",
            "Speed: 6.0ms preprocess, 345.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 315.7ms\n",
            "Speed: 5.5ms preprocess, 315.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 318.9ms\n",
            "Speed: 4.5ms preprocess, 318.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.4ms\n",
            "Speed: 3.7ms preprocess, 324.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 315.1ms\n",
            "Speed: 4.5ms preprocess, 315.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 339.9ms\n",
            "Speed: 3.8ms preprocess, 339.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.8ms\n",
            "Speed: 3.9ms preprocess, 323.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 330.8ms\n",
            "Speed: 3.6ms preprocess, 330.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 336.2ms\n",
            "Speed: 6.1ms preprocess, 336.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.2ms\n",
            "Speed: 3.6ms preprocess, 324.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 349.3ms\n",
            "Speed: 4.1ms preprocess, 349.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 330.5ms\n",
            "Speed: 4.2ms preprocess, 330.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.5ms\n",
            "Speed: 3.5ms preprocess, 331.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 367.5ms\n",
            "Speed: 5.8ms preprocess, 367.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 508.8ms\n",
            "Speed: 4.6ms preprocess, 508.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 505.6ms\n",
            "Speed: 5.7ms preprocess, 505.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 494.6ms\n",
            "Speed: 4.1ms preprocess, 494.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 500.6ms\n",
            "Speed: 4.6ms preprocess, 500.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 506.7ms\n",
            "Speed: 5.0ms preprocess, 506.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 503.7ms\n",
            "Speed: 4.6ms preprocess, 503.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 530.2ms\n",
            "Speed: 4.6ms preprocess, 530.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 344.8ms\n",
            "Speed: 6.0ms preprocess, 344.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 337.0ms\n",
            "Speed: 3.5ms preprocess, 337.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.3ms\n",
            "Speed: 7.9ms preprocess, 322.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 322.0ms\n",
            "Speed: 3.6ms preprocess, 322.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 339.7ms\n",
            "Speed: 3.7ms preprocess, 339.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.3ms\n",
            "Speed: 4.1ms preprocess, 324.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.1ms\n",
            "Speed: 3.5ms preprocess, 324.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 327.7ms\n",
            "Speed: 5.6ms preprocess, 327.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 325.4ms\n",
            "Speed: 3.7ms preprocess, 325.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 340.9ms\n",
            "Speed: 4.0ms preprocess, 340.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.0ms\n",
            "Speed: 4.1ms preprocess, 332.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 335.9ms\n",
            "Speed: 3.5ms preprocess, 335.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 350.6ms\n",
            "Speed: 4.5ms preprocess, 350.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 335.8ms\n",
            "Speed: 3.6ms preprocess, 335.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 352.2ms\n",
            "Speed: 4.1ms preprocess, 352.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 329.1ms\n",
            "Speed: 4.3ms preprocess, 329.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 325.5ms\n",
            "Speed: 3.7ms preprocess, 325.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 352.4ms\n",
            "Speed: 3.8ms preprocess, 352.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.1ms\n",
            "Speed: 3.9ms preprocess, 326.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 341.7ms\n",
            "Speed: 4.7ms preprocess, 341.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.6ms\n",
            "Speed: 4.5ms preprocess, 324.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 327.8ms\n",
            "Speed: 3.5ms preprocess, 327.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 348.5ms\n",
            "Speed: 3.6ms preprocess, 348.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 327.2ms\n",
            "Speed: 4.6ms preprocess, 327.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 339.9ms\n",
            "Speed: 3.7ms preprocess, 339.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 492.7ms\n",
            "Speed: 3.7ms preprocess, 492.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 516.5ms\n",
            "Speed: 6.6ms preprocess, 516.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 497.4ms\n",
            "Speed: 4.2ms preprocess, 497.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 516.4ms\n",
            "Speed: 5.3ms preprocess, 516.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 491.9ms\n",
            "Speed: 6.9ms preprocess, 491.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 522.0ms\n",
            "Speed: 8.3ms preprocess, 522.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 486.0ms\n",
            "Speed: 7.3ms preprocess, 486.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.6ms\n",
            "Speed: 4.7ms preprocess, 332.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 328.6ms\n",
            "Speed: 4.2ms preprocess, 328.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 353.1ms\n",
            "Speed: 3.6ms preprocess, 353.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.6ms\n",
            "Speed: 7.1ms preprocess, 324.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.9ms\n",
            "Speed: 4.6ms preprocess, 331.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 329.7ms\n",
            "Speed: 7.7ms preprocess, 329.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 336.5ms\n",
            "Speed: 7.2ms preprocess, 336.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 359.1ms\n",
            "Speed: 4.9ms preprocess, 359.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.6ms\n",
            "Speed: 5.2ms preprocess, 323.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 323.6ms\n",
            "Speed: 3.6ms preprocess, 323.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 337.3ms\n",
            "Speed: 5.5ms preprocess, 337.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 328.2ms\n",
            "Speed: 5.5ms preprocess, 328.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 348.6ms\n",
            "Speed: 4.4ms preprocess, 348.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 321.1ms\n",
            "Speed: 4.1ms preprocess, 321.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 325.1ms\n",
            "Speed: 4.1ms preprocess, 325.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 332.8ms\n",
            "Speed: 3.7ms preprocess, 332.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.7ms\n",
            "Speed: 4.0ms preprocess, 319.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 328.2ms\n",
            "Speed: 3.7ms preprocess, 328.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 335.3ms\n",
            "Speed: 3.7ms preprocess, 335.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 333.8ms\n",
            "Speed: 3.6ms preprocess, 333.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 336.9ms\n",
            "Speed: 3.7ms preprocess, 336.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 324.6ms\n",
            "Speed: 3.9ms preprocess, 324.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.3ms\n",
            "Speed: 3.6ms preprocess, 326.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 331.4ms\n",
            "Speed: 7.6ms preprocess, 331.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 386.7ms\n",
            "Speed: 3.8ms preprocess, 386.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 517.8ms\n",
            "Speed: 5.5ms preprocess, 517.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 497.7ms\n",
            "Speed: 5.5ms preprocess, 497.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 504.7ms\n",
            "Speed: 10.0ms preprocess, 504.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 489.0ms\n",
            "Speed: 6.3ms preprocess, 489.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 534.3ms\n",
            "Speed: 3.6ms preprocess, 534.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 488.8ms\n",
            "Speed: 9.4ms preprocess, 488.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 507.7ms\n",
            "Speed: 6.4ms preprocess, 507.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 319.8ms\n",
            "Speed: 4.4ms preprocess, 319.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 341.4ms\n",
            "Speed: 4.9ms preprocess, 341.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 338.7ms\n",
            "Speed: 3.6ms preprocess, 338.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 337.2ms\n",
            "Speed: 4.9ms preprocess, 337.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 320.9ms\n",
            "Speed: 3.6ms preprocess, 320.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 326.7ms\n",
            "Speed: 4.2ms preprocess, 326.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Release the video capture object and close the display window\n",
        "videoCap.release()\n",
        "out.release()\n",
        "csv_file.close()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "T79jYYemRF-Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-vhWGmNQRF4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}